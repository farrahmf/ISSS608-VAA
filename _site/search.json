[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This site was created as a requirement of the Singapore Management University’s ISSS608 Visual Analytics and Applications course (January 2023 term). The site creator is a student in the university’s Master of Information Technology in Business (MITB).\nThank you for visiting.\n\nfarrahmf"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The code below uses the pacman package’s p_load() to check if tidyverse is installed. If it is, it will be launched into R.\n\npacman::p_load(tidyverse)\n\n\n\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x = RACE)) +\n  geom_bar()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "1. Installing packages\n\npacman::p_load(ggiraph, plotly, gganimate, DT, patchwork, tidyverse)\n\n\n\n2. Importing data\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n3. Tooltip\nUsing aesthetic tooltip = ID and girafe() to display the id of an element when the mouse hovers over it.\n\np <- ggplot(data = exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\"\n  ) +\n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(ggobj = p,\n       width_svg = 6,\n       height_svg = 6*0.618)\n\n\n\n\n\nDisplaying customised information by creating a new object.\ngirafe(ggobj = p,\nwidth_svg = 8,\nheight_svg = 8*0.618\n)\n\nexam_data$tooltip <- c(paste0(\n  \"Name = \", exam_data$ID,\n  \"\\n Class = \", exam_data$CLASS\n))\n\np <- ggplot(data = exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\"\n  ) +\n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(ggobj = p,\n       width_svg = 8,\n       height_svg = 8*0.618\n)\n\n\n\n\n\nCustomise tooltop style using opts_tooltip() and css declarations.\n\ntooltip_css <- \"background-color:DarkSlateGrey; font-family: Arial, Times, serif; color:LightYellow;\"\n\np <- ggplot(data = exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\"\n  ) +\n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(ggobj = p,\n       width_svg = 8,\n       height_svg = 8*0.618,\n       options = list(\n         opts_tooltip(\n           css = tooltip_css\n         )\n       )\n)\n\n\n\n\n\nDisplaying statistics on tooltip.\n\ntooltip <- function(y, ymax, accuracy = .01) {\n  mean <- scales::number(y, accuracy = accuracy)\n  sem <- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point <- ggplot(data = exam_data,\n                   aes(x = RACE)) +\n  stat_summary(aes(y = MATHS,\n                   tooltip = after_stat(\n                     tooltip(y, ymax))), \n               fun.data = \"mean_se\",\n               geom = GeomInteractiveCol,\n               fill = \"#66CC99\") +\n  stat_summary(aes(y = MATHS),\n               fun.data = mean_se,\n               geom = \"errorbar\", width = 0.2, linewidth = 0.2)\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\nWarning: Using the `size` aesthetic in this geom was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` in the `default_aes` field and elsewhere instead.\n\n\n\n\n\n\nHighlighting elements associated with a data_id.\n\np <- ggplot(data = exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(data_id = CLASS),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\"\n  ) +\n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(ggobj = p,\n       width_svg = 8,\n       height_svg = 8*0.618\n)\n\n\n\n\n\nAs above, but inverting the highlight (i.e. lowlighting elements not associated with the data_id instead).\n\np <- ggplot(data = exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(data_id = CLASS),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\"\n  ) +\n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(ggobj = p,\n       width_svg = 8,\n       height_svg = 8*0.618,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n       )\n)\n\n\n\n\n\nUsing onclick to link to a website.\n\nexam_data$onclick <- sprintf(\"window.open(\\\"%s%s\\\")\",\n                             \"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\", \n                             as.character(exam_data$ID))\n\np <- ggplot(data = exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(onclick = onclick),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\"\n  ) +\n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(ggobj = p,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\nCoordinated multiple views, using ggiraph and patchwork: when a data point on one plot is selected, the corresponding data point (i.e. sharing the same data ID) in another plot will be highlighted too.\n\np1 <- ggplot(data = exam_data,\n             aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(data_id = ID),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\"\n  ) +\n  coord_cartesian(xlim = c(0,100)) +\n  scale_y_continuous(NULL, breaks = NULL)\n\np2 <- ggplot(data = exam_data,\n             aes(x = ENGLISH)) +\n  geom_dotplot_interactive(\n    aes(data_id = ID),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\"\n  ) +\n  coord_cartesian(xlim = c(0,100)) +\n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(code = print(p1/p2),\n       width_svg = 6,\n       height_svg = 6,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2\")\n       )\n       )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html",
    "title": "Hands-on Exercise 4(1)",
    "section": "",
    "text": "pacman::p_load(ggstatsplot, rstantools, PMCMRplus, tidyverse)\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nUsing gghistostats().\n\nset.seed(1234)\n\ngghistostats(\n  data = exam_data,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\nUsing ggbetweenstats().\n\nggbetweenstats(\n  data = exam_data,\n  x = GENDER,\n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\nUsing ggbetweenstats().\n\nggbetweenstats(\n  data = exam_data,\n  x = RACE,\n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE,\n  pairwise.comparisons = TRUE,\n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\nUsing ggscatterscats().\n\nggscatterstats(\n  data = exam_data,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE\n)\n\n\n\n\n\n\n\nUsing ggbarstats().\n\nexam1 <- exam_data %>%\n  mutate(MATHS_bins =\n           cut(MATHS,\n               breaks = c(0, 60, 75, 85, 100)))\n\nggbarstats(exam1,\n           x = MATHS_bins,\n           y = GENDER)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#visualising-models",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#visualising-models",
    "title": "Hands-on Exercise 4(1)",
    "section": "Visualising Models",
    "text": "Visualising Models\n\nLoading packages and installing data\n\npacman::p_load(readxl, performance, parameters, see)\n\ncar_resale <- read_xls(\"data/ToyotaCorolla.xls\", \"data\")\n\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model       Price Age_0…¹ Mfg_M…² Mfg_Y…³     KM Quart…⁴ Weight Guara…⁵\n   <dbl> <chr>       <dbl>   <dbl>   <dbl>   <dbl>  <dbl>   <dbl>  <dbl>   <dbl>\n 1    81 TOYOTA Cor… 18950      25       8    2002  20019     100   1180       3\n 2     1 TOYOTA Cor… 13500      23      10    2002  46986     210   1165       3\n 3     2 TOYOTA Cor… 13750      23      10    2002  72937     210   1165       3\n 4     3  TOYOTA Co… 13950      24       9    2002  41711     210   1165       3\n 5     4 TOYOTA Cor… 14950      26       7    2002  48000     210   1165       3\n 6     5 TOYOTA Cor… 13750      30       3    2002  38500     210   1170       3\n 7     6 TOYOTA Cor… 12950      32       1    2002  61000     210   1170       3\n 8     7  TOYOTA Co… 16900      27       6    2002  94612     210   1245       3\n 9     8 TOYOTA Cor… 18600      30       3    2002  75889     210   1245       3\n10    44 TOYOTA Cor… 16950      27       6    2002 110404     234   1255       3\n# … with 1,426 more rows, 28 more variables: HP_Bin <chr>, CC_bin <chr>,\n#   Doors <dbl>, Gears <dbl>, Cylinders <dbl>, Fuel_Type <chr>, Color <chr>,\n#   Met_Color <dbl>, Automatic <dbl>, Mfr_Guarantee <dbl>,\n#   BOVAG_Guarantee <dbl>, ABS <dbl>, Airbag_1 <dbl>, Airbag_2 <dbl>,\n#   Airco <dbl>, Automatic_airco <dbl>, Boardcomputer <dbl>, CD_Player <dbl>,\n#   Central_Lock <dbl>, Powered_Windows <dbl>, Power_Steering <dbl>,\n#   Radio <dbl>, Mistlamps <dbl>, Sport_Model <dbl>, Backseat_Divider <dbl>, …\n\n\n\n\nMultiple Regression Model\nUsing lm() from Base Stats of R.\n\nmodel <- lm(Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period,\n            data = car_resale)\n\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\n\nModel Diagnostic: Checking for multicollinearity\nUsing check_collinearity() from the performance package.\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Guarantee_Period  1.04   [1.01, 1.17]         1.02      0.97     [0.86, 0.99]\n        Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n         Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\nHigh Correlation\n\n   Term  VIF   VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n     KM 1.46 [1.37, 1.57]         1.21      0.68     [0.64, 0.73]\n Weight 1.41 [1.32, 1.51]         1.19      0.71     [0.66, 0.76]\n\n\n\ncheck_c <- check_collinearity(model)\nplot(check_c)\n\nVariable `Component` is not in your data frame :/\n\n\n\n\n\n\n\nModel Diagnostic: Checking normality assumption\nUsing check_normality() from the performance package.\n\nmodel1 <- lm(Price ~ Age_08_04 + KM + Weight + Guarantee_Period,\n             data = car_resale)\n\ncheck_n <- check_normality(model1)\n\nplot(check_n)\n\n\n\n\n\n\nModel Diagnostic: Checking for heteroscedasticity\nUsing check_heteroscedasticity() from the performance package.\n\ncheck_h <- check_heteroscedasticity(model1)\n\nplot(check_h)\n\n\n\n\n\n\nModel Diagnostic: Complete check\nUsing check_model().\n\ncheck_model(model1)\n\nVariable `Component` is not in your data frame :/\n\n\n\n\n\n\n\nVisualising Regression Parameters\nUsing plot() of see package and parameters() of parameters package to visualise the parameters of a regression model.\n\nplot(parameters(model1))\n\n\n\n\nUsing ggcoefstats() of ggstatsplot package to visualise the parameters of a regression model.\n\nggcoefstats(model1, output = \"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html",
    "title": "Hands-on Exercise 4(2)",
    "section": "",
    "text": "pacman::p_load(plotly, crosstalk, DT, ggiraph, ggdist, gganimate, tidyverse)\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nUsing ggplot2. First, group observations and tabulate count, mean, standard deviation and standard error for each group.\n\nmy_sum <- exam_data %>%\n  group_by(RACE) %>%\n  summarise(\n    n = n(),\n    mean = mean(MATHS),\n    sd = sd(MATHS)\n  ) %>%\n  mutate(se = sd/sqrt(n-1))\n\nmy_sum\n\n# A tibble: 4 × 5\n  RACE        n  mean    sd    se\n  <chr>   <int> <dbl> <dbl> <dbl>\n1 Chinese   193  76.5  15.7  1.13\n2 Indian     12  60.7  23.4  7.04\n3 Malay     108  57.4  21.1  2.04\n4 Others      9  69.7  10.7  3.79\n\n\nVisualise as a table, using kable().\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n \n  \n    RACE \n    n \n    mean \n    sd \n    se \n  \n \n\n  \n    Chinese \n    193 \n    76.50777 \n    15.69040 \n    1.132357 \n  \n  \n    Indian \n    12 \n    60.66667 \n    23.35237 \n    7.041005 \n  \n  \n    Malay \n    108 \n    57.44444 \n    21.13478 \n    2.043177 \n  \n  \n    Others \n    9 \n    69.66667 \n    10.72381 \n    3.791438 \n  \n\n\n\n\n\nVisualising on a chart.\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean \n          maths score by race\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n# for 95% confidence interval, ordered by mean\n\ntcrit <- qnorm(0.025)\n\nmy_sum$tooltip <- c(paste0(\n  \"Race = \", my_sum$RACE,\n  \"\\n N = \", my_sum$n,\n  \"\\n Avg. Scores = \", my_sum$mean,\n  \"\\n 95% CI: [\", my_sum$mean-(tcrit*my_sum$se), \" , \", my_sum$mean+(tcrit*my_sum$se), \"]\"\n))\n\np <- ggplot(my_sum) +\n  geom_errorbar(\n    aes(x = reorder(RACE, -mean), ymin = mean-(tcrit*se), ymax = mean+(tcrit*se)),\n    width = 0.2, colour = \"black\", alpha = 0.9, size = 0.5) +\n  geom_point_interactive(\n    aes(x = reorder(RACE, -mean), y = mean, tooltip = my_sum$tooltip), \n    stat = \"identity\", colour = \"red\", size = 1.5, alpha = 1) +\n  ggtitle(\"Standard error of mean maths score by race\")\n\ngirafe(ggobj = p,\n       width_svg = 8,\n       height_svg = 8*0.618\n)\n\nWarning: Use of `my_sum$tooltip` is discouraged.\nℹ Use `tooltip` instead.\n\n\n\n\n\n\n\n\n\nUsing stat_pointinterval() to build a visual for displaying distribution of maths scores by race.\n\nexam_data %>%\n  ggplot(aes(x = RACE,\n             y = MATHS)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\"\n  )\n\n\n\n\nNote: for the below, from prof’s slides, .point and .interval are ignored, replaced by point_interval per documentation however using point_interval = “median.qi” does not work. Resulting chart looks the same though.\n\nexam_data %>%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95) +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\nMakeover the plot on previous slide by showing 95% and 99% confidence intervals.\n\nexam_data %>%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = c(0.95,0.99)) +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\nUsing stat_gradientinterval() from ggdist package to build a visual displaying distribution of maths scores by race.\n\nexam_data %>%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")\n\nWarning: fill_type = \"gradient\" is not supported by the current graphics device.\n - Falling back to fill_type = \"segments\".\n - If you believe your current graphics device *does* support\n   fill_type = \"gradient\" but auto-detection failed, set that option\n   explicitly and consider reporting a bug.\n - See help(\"geom_slabinterval\") for more information.\n\n\n\n\n\n\n\n\n(Hypothetical Outcome Plots)\nNot able to run the code and including it prevents successful rendering of website."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html",
    "title": "Hands-on Exercise 4(3)",
    "section": "",
    "text": "pacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)\n\ncovid19 <- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %>%\n  mutate_if(is.character, as.factor)\n\nRows: 267 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): City, District, Sub-district\ndbl (4): Sub-district ID, Positive, Recovered, Death\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ncovid19\n\n# A tibble: 267 × 7\n   `Sub-district ID` City            District      Sub-d…¹ Posit…² Recov…³ Death\n               <dbl> <fct>           <fct>         <fct>     <dbl>   <dbl> <dbl>\n 1        3172051003 JAKARTA UTARA   PADEMANGAN    ANCOL      1776    1691    26\n 2        3173041007 JAKARTA BARAT   TAMBORA       ANGKE      1783    1720    29\n 3        3175041005 JAKARTA TIMUR   KRAMAT JATI   BALE K…    2049    1964    31\n 4        3175031003 JAKARTA TIMUR   JATINEGARA    BALI M…     827     797    13\n 5        3175101006 JAKARTA TIMUR   CIPAYUNG      BAMBU …    2866    2792    27\n 6        3174031002 JAKARTA SELATAN MAMPANG PRAP… BANGKA     1828    1757    26\n 7        3175051002 JAKARTA TIMUR   PASAR REBO    BARU       2541    2433    37\n 8        3175041004 JAKARTA TIMUR   KRAMAT JATI   BATU A…    3608    3445    68\n 9        3171071002 JAKARTA PUSAT   TANAH ABANG   BENDUN…    2012    1937    38\n10        3175031002 JAKARTA TIMUR   JATINEGARA    BIDARA…    2900    2773    52\n# … with 257 more rows, and abbreviated variable names ¹​`Sub-district`,\n#   ²​Positive, ³​Recovered\n\n\nBasic funnel plot.\n\nfunnel_plot(\n  numerator = covid19$Positive,\n  denominator = covid19$Death,\n  group = covid19$`Sub-district`\n)\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\nMade over by changing data type to proportions and recalibrating the x and y axes…\n\nfunnel_plot(\n  numerator = covid19$Death,\n  denominator = covid19$Positive,\n  group = covid19$`Sub-district`,\n  data_type = \"PR\",   \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #<<           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #<<\n  y_label = \"Cumulative Fatality Rate\"  #<<\n)\n\nWarning: The `xrange` argument deprecated; please use the `x_range` argument\ninstead.  For more options, see the help: `?funnel_plot`\n\n\nWarning: The `yrange` argument deprecated; please use the `y_range` argument\ninstead.  For more options, see the help: `?funnel_plot`\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n… with more appropriate labelling\n\nfunnel_plot(\n  numerator = covid19$Death,\n  denominator = covid19$Positive,\n  group = covid19$`Sub-district`,\n  data_type = \"PR\",   \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #<<           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #<<\n  y_label = \"Cumulative Fatality Rate\"  #<<\n)\n\nWarning: The `xrange` argument deprecated; please use the `x_range` argument\ninstead.  For more options, see the help: `?funnel_plot`\n\n\nWarning: The `yrange` argument deprecated; please use the `y_range` argument\ninstead.  For more options, see the help: `?funnel_plot`\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#funnel-plots-using-ggplot2",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#funnel-plots-using-ggplot2",
    "title": "Hands-on Exercise 4(3)",
    "section": "Funnel plots using ggplot2",
    "text": "Funnel plots using ggplot2\nFirst, derive cumulative death rate and its standard error.\n\ndf <- covid19 %>%\n  mutate(rate = Death / Positive) %>%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %>%\n  filter(rate > 0)\n\nCompute fit.mean (what is?)\n\nfit.mean <- weighted.mean(df$rate, 1/df$rate.se^2)\n\nCalculate the 95% and 99% confidence intervals\n\nnumber.seq <- seq(1, max(df$Positive), 1)\nnumber.ll95 <- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 <- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 <- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 <- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI <- data.frame(number.ll95, number.ul95, number.ll999, number.ul999, number.seq, fit.mean)\n\nPlotting a static funnel plot (note that “label” is not recognised below, but is needed later for the interactive)\n\np <- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            linewidth = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            linewidth = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            linewidth = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            linewidth = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             linewidth = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\n\nWarning in geom_point(aes(label = `Sub-district`), alpha = 0.4): Ignoring\nunknown aesthetics: label\n\np\n\n\n\n\nMaking it interactive.\n\nfp_ggplotly <- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on Exercise 5(1)",
    "section": "",
    "text": "pacman::p_load(ggtern, plotly, tidyverse)\npop_data <- read_csv(\"data/respopagsex2000to2018_tidy.csv\")\n\nDerive three new variables - ‘YOUNG’, ‘ACTIVE’ and ‘OLD’ - from the existing age group variables.\n\nagpop_mutated <- pop_data %>%\n  mutate('Year' = as.character(Year)) %>%\n  spread(AG, Population) %>%\n  mutate(YOUNG = rowSums(.[4:8])) %>%\n  mutate(ACTIVE = rowSums(.[9:16])) %>%\n  mutate(OLD = rowSums(.[17:21])) %>%\n  mutate(TOTAL = rowSums(.[22:24])) %>%\n  filter(Year == 2018) %>%\n  filter(TOTAL > 0)\n\n\n\n\nStatic:\n\nggtern(data = agpop_mutated, aes(x = YOUNG, y = ACTIVE, z = OLD)) +\n  geom_point() +\n  labs(title = \"Population structure, 2015\") +\n  theme_rgbw()\n\n\n\n\nInteractive:\n\nlabel <- function(txt) {\n  list(\n    text = txt,\n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\",\n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\naxis <- function(txt) {\n  list(title = txt, tickformat = \".0%\", tickfont = list(size = 10))\n}\n\nternaryAxes <- list(\n  aaxis = axis(\"Young\"),\n  baxis = axis(\"Active\"),\n  caxis = axis(\"Old\")\n)\n\nplot_ly(\n  agpop_mutated,\n  a = ~YOUNG,\n  b = ~ACTIVE,\n  c = ~OLD,\n  color = I(\"black\"),\n  type = \"scatterternary\"\n) %>%\n  layout(\n    annotations = label(\"Ternary Markers\"),\n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_2.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_2.html",
    "title": "Hands-on Exercise 5(2)",
    "section": "",
    "text": "Correlation Matrices\n\nLoading packages and importing data\n\npacman::p_load(corrplot, ggstatsplot, tidyverse)\nwine <- read_csv(\"data/wine_quality.csv\")\n\n\n\nUsing pairs()\n\npairs(wine[,1:11])\n\n\n\n\n\npairs(wine[,2:12], lower.panel = NULL)\n\n\n\n\nShowing the correlation coefficient of each pair of variables:\n\npanel.cor <- function(x, y, digits = 2, prefix = \"\", cex.cor, ...) {\n  usr <- par(\"usr\")\n  on.exit(par(usr))\n  par(usr = c(0, 1, 0, 1))\n  r <- abs(cor(x, y, use = \"complete.obs\"))\n  txt <- format(c(r, 0.123456789), digits = digits)[1]\n  txt <- paste(prefix, txt, sep = \"\")\n  if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)\n  text(0.5, 0.5, txt, cex = cex.cor * (1 + r)/2)\n}\n\npairs(wine[,2:12], upper.panel = panel.cor)\n\n\n\n\n\n\nUsing ggcorrmat()\nCode below won’t run, error message:\nError in titleGrob(label, x, y, hjust = hj, vjust = vj, angle = angle, :\nunused argument (expand_y = TRUE)\n\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)\n\n\n\n\n\n\nUsing corrplot()\n\nwine.cor <- cor(wine[, 1:11])\ncorrplot(wine.cor, method = \"shade\", type = \"lower\", diag = FALSE, tl.col = \"black\")\n\n\n\n\nCombining with significance test:\n\nwine.sig = cor.mtest(wine.cor, conf.level = 0.95)\n\n\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05)\n\n\n\n\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")\n\n\n\n\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order=\"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_3.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_3.html",
    "title": "Hands-on Exercise 5(3)",
    "section": "",
    "text": "pacman::p_load(seriation, dendextend, heatmaply, tidyverse)\nwh <- read_csv(\"data/WHData-2018.csv\")\n\n\n\n\nReplace the row names (currently just numbers) with their corresponding country names:\n\nrow.names(wh) <- wh$Country\n\nTransforming to a data matrix:\n\nwh1 <- dplyr::select(wh, c(3, 7:12))  ## what is this for?\nwh_matrix <- data.matrix(wh)\nwh_matrix1 <- data.matrix(wh1) ## added\n\nStatic heatmap with column value indicated by colour intensity:\n\nwh_heatmap <- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "title": "Interactivity",
    "section": "",
    "text": "Installing and loading R packages\nTwo packages will be installed and loaded. They are: tidyverse and ggiraph.\n\npacman::p_load(ggiraph, tidyverse)\n\n\n\nImporting data\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nStatic plot:\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(dotsize = 0.5)\n\n\n\n\nInteractive plot using ggiraph:\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "Statistical Analysis",
    "section": "",
    "text": "pacman::p_load(plotly, DT, patchwork, ggstatsplot, ggside, tidyverse)\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\n\nplot_ly(data = exam_data,\n        x = ~ENGLISH,\n        y = ~MATHS,\n        color = ~RACE)\n\n\n\n\n\n\np <- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(dotsize = 1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p) #<<\n\n\n\n\n\n\nggbetweenstats(\n  data = exam_data,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\", # non-parametric\n  messages = FALSE\n)\n\n\n\n\n\nggscatterstats(\n  data = exam_data,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\nggscatterstats(\n  data = exam_data,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = TRUE,\n  )\n\n\n\n\n\npacman::p_load(readxl, performance, parameters, see, gtsummary)\n\n\ncar_resale <- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model       Price Age_0…¹ Mfg_M…² Mfg_Y…³     KM Quart…⁴ Weight Guara…⁵\n   <dbl> <chr>       <dbl>   <dbl>   <dbl>   <dbl>  <dbl>   <dbl>  <dbl>   <dbl>\n 1    81 TOYOTA Cor… 18950      25       8    2002  20019     100   1180       3\n 2     1 TOYOTA Cor… 13500      23      10    2002  46986     210   1165       3\n 3     2 TOYOTA Cor… 13750      23      10    2002  72937     210   1165       3\n 4     3  TOYOTA Co… 13950      24       9    2002  41711     210   1165       3\n 5     4 TOYOTA Cor… 14950      26       7    2002  48000     210   1165       3\n 6     5 TOYOTA Cor… 13750      30       3    2002  38500     210   1170       3\n 7     6 TOYOTA Cor… 12950      32       1    2002  61000     210   1170       3\n 8     7  TOYOTA Co… 16900      27       6    2002  94612     210   1245       3\n 9     8 TOYOTA Cor… 18600      30       3    2002  75889     210   1245       3\n10    44 TOYOTA Cor… 16950      27       6    2002 110404     234   1255       3\n# … with 1,426 more rows, 28 more variables: HP_Bin <chr>, CC_bin <chr>,\n#   Doors <dbl>, Gears <dbl>, Cylinders <dbl>, Fuel_Type <chr>, Color <chr>,\n#   Met_Color <dbl>, Automatic <dbl>, Mfr_Guarantee <dbl>,\n#   BOVAG_Guarantee <dbl>, ABS <dbl>, Airbag_1 <dbl>, Airbag_2 <dbl>,\n#   Airco <dbl>, Automatic_airco <dbl>, Boardcomputer <dbl>, CD_Player <dbl>,\n#   Central_Lock <dbl>, Powered_Windows <dbl>, Power_Steering <dbl>,\n#   Radio <dbl>, Mistlamps <dbl>, Sport_Model <dbl>, Backseat_Divider <dbl>, …\n\n\n\nmodel <- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\ntable1 <- tbl_regression(model, intercept = TRUE)\n\ntable1\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n-2,636,783\n-3,150,331, -2,123,236\n<0.001\n    Age_08_04\n-14\n-35, 7.1\n0.2\n    Mfg_Year\n1,315\n1,059, 1,571\n<0.001\n    KM\n-0.02\n-0.03, -0.02\n<0.001\n    Weight\n19\n17, 21\n<0.001\n    Guarantee_Period\n28\n3.8, 52\n0.023\n  \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\n\ncheck_c <- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\nmodel1 <- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\n\ncheck_n <- check_normality(model1)\n\n\nplot(check_n)\n\n\n\n\n\ncheck_model(model1)\n\n\n\n\n\nplot(parameters(model1))\n\n\n\n\n\nggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "Correlation Matrices",
    "section": "",
    "text": "pacman::p_load(corrplot, tidyverse, ggstatsplot)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#correlation-matrices",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#correlation-matrices",
    "title": "Correlation Matrices",
    "section": "Correlation Matrices",
    "text": "Correlation Matrices\n\nggstatsplot::ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  ggcorrplot.args = list(outline.color = \"black\",\n                         hc.order = TRUE,\n                         tl.cex = 15),  ## \"X\" size\n  title = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are not significant at p < 0.05\"\n)\n\n\n\n\n\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)\n\n\n\n\n\nwine.cor <- cor(wine[, 1:11])\n\n\ncorrplot(wine.cor,\n         method = \"ellipse\",\n         type=\"lower\",\n         diag = FALSE,\n         tl.col = \"black\")\n\n\n\n\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\nwine.sig = cor.mtest(wine.cor, conf.level= .95)\n\n\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05)\n\n\n\n\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")\n\n\n\n\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order=\"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05_2.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05_2.html",
    "title": "Ternary Plots and Heat Maps",
    "section": "",
    "text": "pacman::p_load(ggtern, plotly, seriation, dendextend, heatmaply, tidyverse)\npop_data <- read_csv(\"data/respopagsex2000to2018_tidy.csv\") \nwh <- read_csv(\"data/WHData-2018.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05_2.html#ternary-plots",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05_2.html#ternary-plots",
    "title": "Ternary Plots and Heat Maps",
    "section": "Ternary Plots",
    "text": "Ternary Plots\n\nagpop_mutated <- pop_data %>%\n  mutate(`Year` = as.character(Year))%>%\n  spread(AG, Population) %>%\n  mutate(YOUNG = rowSums(.[4:8]))%>%\n  mutate(ACTIVE = rowSums(.[9:16]))  %>%\n  mutate(OLD = rowSums(.[17:21])) %>%\n  mutate(TOTAL = rowSums(.[22:24])) %>%\n  filter(Year == 2018)%>%\n  filter(TOTAL > 0)\n\n\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()\n\n\n\n\n\nlabel <- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\naxis <- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes <- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %>%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05_2.html#heat-maps",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05_2.html#heat-maps",
    "title": "Ternary Plots and Heat Maps",
    "section": "Heat Maps",
    "text": "Heat Maps\n\nStatic\n\nrow.names(wh) <- wh$Country\nwh_matrix <- data.matrix(wh)\n\n\nwh_heatmap <- heatmap(wh_matrix)\n\n\n\n\n\nwh_heatmap <- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))\n\n\n\n\n\n\nInteractive\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)\n\n\n\n\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05_3.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05_3.html",
    "title": "Parallel Coordinates Plots",
    "section": "",
    "text": "Loading Packages and Importing Dataset\n\npacman::p_load(GGally, parallelPlot, tidyverse)\nwh <- read_csv(\"data/WHData-2018.csv\")\n\nUsing boxplot()\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\")\n\n\n\n\nWith facet wrap and x-axis labels at 30 deg rotation.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\n\n\nUsing parallelPlot\n\nwh <- wh %>%\n  select(\"Happiness score\", c(7:12))\nparallelPlot(wh,\n             width = 320,\n             height = 250,\n             rotateTitle = TRUE)\n\n\n\n\n\nwith histogram\n\nhistoVisibility <- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "title": "In-class Exercise 6",
    "section": "",
    "text": "This exercise is about working with temporal data.\n\n\n\npacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, tidyverse, readxl, knitr, data.table)\n\n\n\n\nWe will use a data file comprising199,999 rows of time-series cyber attack records, by country.\nImporting the dataset:\n\nattacks <- read_csv(\"data/eventlog.csv\")\n\nExamining the data structure using kable().\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nWe note that:\n\ntimestamp field stores date-time values in POSIXct format (Note: POSIXct stores date and time in seconds with the number of seconds beginning at 1 January 1970. Each date and time is thus a single value in units of seconds. This speeds up computation, processing and conversion to other formats.)\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code\ntz field stores time zone of the source IP address\n\n\n\nStep 1: Deriving wkday and hour fields to enable plotting of the calendar heatmap.\n\nmake_hr_wkday <- function(ts, sc, tz) {\n  real_times <- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt <- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\nStep 2: Deriving the attacks tibble data frame.\n\nwkday_levels <- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks <- attacks %>%\n  group_by(tz) %>%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %>% \n  ungroup() %>% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\nNote: The use of factor() ensures that those variables are ordered during plotting.\nChecking the structure of attacks.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\n\n…\n\ngrouped <- attacks %>% \n  count(wkday, hour) %>% \n  ungroup() %>%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          linewidth = 0.1) + \ntheme_tufte(base_family = \"serif\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\n[NOTES]\n\n\n\nSteps 1 and 2 will identify and extract data on the top 4 countries in terms of number of attacks.\nStep 1: Deriving attack by country object\n\nattacks_by_country <- count(\n  attacks, source_country) %>%\n  mutate(percent = percent(n/sum(n))) %>%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\n\ntop4 <- attacks_by_country$source_country[1:4]\ntop4_attacks <- attacks %>%\n  filter(source_country %in% top4) %>%\n  count(source_country, wkday, hour) %>%\n  ungroup() %>%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %>%\n  na.omit()\n\nNow we plot the multiple heat map using ggplot2.\nStep 3: Plotting the Multiple Calender Heatmaps\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"serif\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\nWe will plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam, using ggplot2.\nImporting the dataset:\n\nair <- read_excel(\"data/arrivals_by_air.xlsx\")\n\n…\n\nair$month <- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year <- year(ymd(air$`Month-Year`))\n\n…\n\nVietnam <- air %>% \n  select(`Vietnam`, \n         month, \n         year) %>%\n  filter(year >= 2010)\n\n…\n\nhline.data <- Vietnam %>% \n  group_by(month) %>%\n  summarise(avgvalue = mean(`Vietnam`))\n\n…\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html",
    "title": "Choropleths",
    "section": "",
    "text": "pacman::p_load(sf, tmap, tidyverse)\n\nThis dataset records the number of Singapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling. (Source: Singapore Department of Statistics)\n\npopdata <- read_csv(\"aspatial/respopagesextod2011to2020.csv\")\n\n\nThis will provide the geospatial data of our area of interest (Singapore), to enable mapping later on. Note that “.shp” files are multifile.\n\nmpsz <- st_read(dsn = \"geospatial\", \n                layer = \"MP14_SUBZONE_WEB_PL\")\n\nReading layer `MP14_SUBZONE_WEB_PL' from data source \n  `C:\\farrahmf\\ISSS608-VAA\\In-class_Ex\\In-class_Ex07\\geospatial' \n  using driver `ESRI Shapefile'\nSimple feature collection with 323 features and 15 fields\nGeometry type: MULTIPOLYGON\nDimension:     XY\nBounding box:  xmin: 2667.538 ymin: 15748.72 xmax: 56396.44 ymax: 50256.33\nProjected CRS: SVY21\n\n\n\nPreparing a data table comprising variables PA, SZ, YOUNG, ECONOMY ACTIVE, AGED, TOTAL and DEPENDENCY, for the year 2020:\n\npopdata2020 <- popdata %>%\n  filter(Time == 2020) %>%\n  group_by(PA, SZ, AG) %>%\n  summarise(`POP` = sum(`Pop`)) %>%\n  ungroup()%>%\n  pivot_wider(names_from=AG, \n              values_from=POP) %>%\n  mutate(YOUNG = rowSums(.[3:6])\n         +rowSums(.[12])) %>%\n  mutate(`ECONOMY ACTIVE` = rowSums(.[7:11]) +\n           rowSums(.[13:15]))%>%\n  mutate(`AGED`=rowSums(.[16:21])) %>% \n  mutate(`TOTAL`=rowSums(.[3:21])) %>%  \n  mutate(`DEPENDENCY` = (`YOUNG` + `AGED`)/`ECONOMY ACTIVE`) %>%\n  select(`PA`, `SZ`, `YOUNG`, \n         `ECONOMY ACTIVE`, `AGED`, \n         `TOTAL`, `DEPENDENCY`)\n\n\nThe PA and SZ variables from popdata2020 are intended to match the PL_AREA_N and SUBZONE_N variables from mpsz. As the former are in a mix of upper and lower case, while the latter are in upper case only, we need to convert the former to upper case only in order to join the two datasets.\n\npopdata2020 <- popdata2020 %>%\n  mutate_at(.vars = vars(PA, SZ), \n          .funs = funs(toupper)) %>%\n  filter(`ECONOMY ACTIVE` > 0)\n\n\nLeft-join popdata2020 to mpsz to ensure the resulting table has complete set of geospatial data to enable mapping later on. Join on condition of matching SZ to SUBZONE_N. (All rows in mpsz would be retained, while only those rows in popdata2020 that match rows in mpsz will be retained.)\n\nmpsz_pop2020 <- left_join(mpsz, popdata2020,\n                          by = c(\"SUBZONE_N\" = \"SZ\"))\n\n\nwrite_rds(mpsz_pop2020, \"rds/mpszpop2020.rds\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#using-tmap",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07.html#using-tmap",
    "title": "Choropleths",
    "section": "Using tmap",
    "text": "Using tmap\nThe function qtm() will quickly draw a cartographic standard choropleth map:\n\ntmap_mode(\"plot\")\nqtm(mpsz_pop2020, \n    fill = \"DEPENDENCY\")\n\n\n\n\n\n(Note: “view” as opposed to “mode” will provide an interactive version. Any subsequent mapping will adopt the last type used, i.e. “view” or “mode”. Also, it won’t work to simply replace “mode” with “view”, other functions are needed (?).)\n\n\nThe disadvantge of qtm() is that it makes aesthetics of individual layers harder to control. To draw a high quality cartographic choropleth map, tmap’s drawing elements should be used.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"Dependency ratio\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar() +\n  tm_grid(alpha =0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n\nDrawing a base map\ntm_shape() : initiates the map\ntm_polygons() : lays on the polygons defining the sub-areas of interest (in this case planning area sub-zones). The argument in the brackets will fill each polygon with a colour corresponding to the value associated with that variable for that sub-area. Values, colour scales and missing values are default. Wrapper for:\n\ntm_fill() : arguments include n (number of classes), style (discrete and continuous gradient options) and most standard aesthetics\ntm_border() : arguments include most standard aesthetics\n\n\ntm_shape(mpsz_pop2020)+\n  tm_polygons(\"DEPENDENCY\")\n\n\n\n\n\n# the \"jenks\" method is somewhere between the \"equal\" and \"quantile\" methods\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"jenks\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"equal\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"sd\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"kmeans\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 5,\n          style = \"pretty\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\n\nSetting break points - start by looking at the descriptive statistics.\n\nsummary(mpsz_pop2020$DEPENDENCY)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA's \n 0.0000  0.6519  0.7025  0.7742  0.7645 19.0000      92 \n\n\n\nBased on the above, we can set break points at 0.60, 0.70, 0.80, and 0.90, with minimum and maximum of 0 and 1.00.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          breaks = c(0, 0.60, 0.70, 0.80, 0.90, 1.00)) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\nChoosing colour schemes from the RColorBrewer palettes.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"BuPu\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\nReverse the colour scheme:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\",\n          n = 6,\n          style = \"quantile\",\n          palette = \"-BuPu\") +\n  tm_borders(alpha = 0.5)\n\n\n\n\nMap layout components include various:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"jenks\", \n          palette = \"BuPu\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(main.title = \"Distribution of Dependency Ratio by planning subzone \\n(Jenks classification)\",\n            main.title.position = \"center\",\n            main.title.size = 1,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            legend.outside = FALSE,\n            legend.position = c(\"RIGHT\", \"BOTTOM\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\nMap style options:\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"classic\")\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"cobalt\")\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"natural\")\n\n\n\n\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"-Greens\") +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"bw\")\n\n\n\n\n\n\nCartographic furniture: tmap also also provides arguments to draw other map furniture such as compass, scale bar and grid lines.\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\",\n          title = \"No. of persons\") +\n  tm_layout(main.title = \"Distribution of Dependency Ratio \\nby planning subzone\",\n            main.title.position = \"center\",\n            main.title.size = 1.2,\n            legend.height = 0.45, \n            legend.width = 0.35,\n            frame = TRUE) +\n  tm_borders(alpha = 0.5) +\n  tm_compass(type=\"8star\", size = 2) +\n  tm_scale_bar(width = 0.15) +\n  tm_grid(lwd = 0.1, alpha = 0.2) +\n  tm_credits(\"Source: Planning Sub-zone boundary from Urban Redevelopment Authorithy (URA)\\n and Population data from Department of Statistics DOS\", \n             position = c(\"left\", \"bottom\"))\n\n\n\n\n \nTo reset to default style:\n\ntmap_style(\"white\")\n\n\n\nDrawing multiple maps\nBy defining ncols in tm_fill():\n\ntm_shape(mpsz_pop2020)+\n  tm_fill(c(\"YOUNG\", \"AGED\"),\n          style = \"equal\", \n          palette = \"Blues\") +\n  tm_layout(legend.position = c(\"right\", \"bottom\")) +\n  tm_borders(alpha = 0.5) +\n  tmap_style(\"white\")\n\n\n\n\n\nOr by assigning multiple values to at least one of the aesthetic arguments:\n\ntm_shape(mpsz_pop2020)+ \n  tm_polygons(c(\"DEPENDENCY\",\"AGED\"),\n          style = c(\"equal\", \"quantile\"), \n          palette = list(\"Blues\",\"Greens\")) +\n  tm_layout(legend.position = c(\"right\", \"bottom\"))\n\n\n\n\n\n\nOr by using tm_facets():\n\ntm_shape(mpsz_pop2020) +\n  tm_fill(\"DEPENDENCY\",\n          style = \"quantile\",\n          palette = \"Blues\",\n          thres.poly = 0) + \n  tm_facets(by=\"REGION_N\", \n            free.coords=TRUE, \n            drop.shapes=TRUE) +\n  tm_layout(legend.show = FALSE,\n            title.position = c(\"center\", \"center\"), \n            title.size = 20) +\n  tm_borders(alpha = 0.5)\n\n\n\n\n\nOr by creating multiple stand-alone maps with tmap_arrange():\n\nyoungmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"YOUNG\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\nagedmap <- tm_shape(mpsz_pop2020)+ \n  tm_polygons(\"AGED\", \n              style = \"quantile\", \n              palette = \"Blues\")\n\ntmap_arrange(youngmap, agedmap, asp=1, ncol=2)\n\n\n\n\n\n\n\n\n\nMapping Spatial Object Meeting a Selection Criterion\n\ntm_shape(mpsz_pop2020[mpsz_pop2020$REGION_N==\"CENTRAL REGION\", ])+\n  tm_fill(\"DEPENDENCY\", \n          style = \"quantile\", \n          palette = \"Blues\", \n          legend.hist = TRUE, \n          legend.is.portrait = TRUE,\n          legend.hist.z = 0.1) +\n  tm_layout(legend.outside = TRUE,\n            legend.height = 0.45, \n            legend.width = 5.0,\n            legend.position = c(\"right\", \"bottom\"),\n            frame = FALSE) +\n  tm_borders(alpha = 0.5)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07_2.html",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07_2.html",
    "title": "Geospatial Point Data",
    "section": "",
    "text": "pacman::p_load(sf, tmap, tidyverse)\n\n\nsgpools <- read_csv(\"aspatial/SGPools_svy21.csv\")\nlist(sgpools)\n\n[[1]]\n# A tibble: 306 × 7\n   NAME                            ADDRESS POSTC…¹ XCOORD YCOORD OUTLE…² Gp1Gp…³\n   <chr>                           <chr>     <dbl>  <dbl>  <dbl> <chr>     <dbl>\n 1 Livewire (Marina Bay Sands)     2 Bayf…   18972 30842. 29599. Branch        5\n 2 Livewire (Resorts World Sentos… 26 Sen…   98138 26704. 26526. Branch       11\n 3 SportsBuzz (Kranji)             Lotus …  738078 20118. 44888. Branch        0\n 4 SportsBuzz (PoMo)               1 Sele…  188306 29777. 31382. Branch       44\n 5 Prime Serangoon North           Blk 54…  552542 32239. 39519. Branch        0\n 6 Singapore Pools Woodlands Cent… 1A Woo…  731001 21012. 46987. Branch        3\n 7 Singapore Pools 64 Circuit Rd … Blk 64…  370064 33990. 34356. Branch       17\n 8 Singapore Pools 88 Circuit Rd … Blk 88…  370088 33847. 33976. Branch       16\n 9 Singapore Pools Anchorvale Rd … Blk 30…  540308 33910. 41275. Branch       21\n10 Singapore Pools Ang Mo Kio N2 … Blk 20…  560202 29246. 38943. Branch       25\n# … with 296 more rows, and abbreviated variable names ¹​POSTCODE,\n#   ²​`OUTLET TYPE`, ³​`Gp1Gp2 Winnings`"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07_2.html#creating-an-sf-data-frame-from-an-aspatial-data-frame",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07_2.html#creating-an-sf-data-frame-from-an-aspatial-data-frame",
    "title": "Geospatial Point Data",
    "section": "Creating an sf data frame from an aspatial data frame",
    "text": "Creating an sf data frame from an aspatial data frame\n\nAccording to Wikipedia, Simple Features (officially Simple Feature Access) is a set of standards that specify a common storage and access model of geographic feature made of mostly two-dimensional geometries (point, line, polygon, multi-point, multi-line, etc.) used by geographic information systems. It is formalized by both the Open Geospatial Consortium (OGC) and the International Organization for Standardization (ISO).\nNote that geographic coordinate systems are not suitable if distances and areas need to be accurate. This is because a degree difference increases in distance the closer the degree is to the equator. Hence projected coordinates are preferred. Projection system coordinates tend to be based on distance (e.g. metres, as in the case for Singapore), rather than degrees of latitude.\nConvert sgpools into a simple feature data frame. A new column called geometry will be added, which has the coordinates in the specified European Petroleum Survey (EPSG) format.\n\nsgpools_sf <- st_as_sf(sgpools, \n                       coords = c(\"XCOORD\", \"YCOORD\"),\n                       crs= 3414)\n\n(Note: The crs argument requires the coordinates system in epsg format.)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07_2.html#drawing-proportional-symbols",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07_2.html#drawing-proportional-symbols",
    "title": "Geospatial Point Data",
    "section": "Drawing Proportional Symbols",
    "text": "Drawing Proportional Symbols\nSet tmap mode to interactive viewing:\n\nMap:\n\ntmap_mode(\"view\")\ntm_shape(sgpools_sf)+\ntm_bubbles(col = \"tomato\",\n           size = 1,\n           border.col = \"black\",\n           border.lwd = 1)\n\n\n\n\n\ntmap_mode(\"plot\")\n\n\nMake it proportional:\n\ntmap_mode(\"view\")\ntm_shape(sgpools_sf)+\ntm_bubbles(\n  col = \"royalblue3\",\n           size = \"Gp1Gp2 Winnings\",\n           border.col = \"azure\",\n           border.lwd = 1)\n\n\n\n\n\ntmap_mode(\"plot\")\n\n\nFill bubble colours by group and create facet plots:\n\ntm_shape(sgpools_sf) +\n  tm_bubbles(col = \"OUTLET TYPE\", \n          size = \"Gp1Gp2 Winnings\",\n          border.col = \"black\",\n          border.lwd = 1) +\n  tm_facets(by= \"OUTLET TYPE\",\n            nrow = 1,\n            sync = TRUE)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07_2.html#remember",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07_2.html#remember",
    "title": "Geospatial Point Data",
    "section": "Remember",
    "text": "Remember\n\nto switch tmap viewer back to “plot” (static) mode at the end of each session!\n\ntmap_mode(\"plot\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07_3.html",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07_3.html",
    "title": "Analytical Mapping",
    "section": "",
    "text": "pacman::p_load(sf, tmap, tidyverse)\n\n\nNGA_wp <- read_rds(\"rds/NGA_wp.rds\")\n\nPlotting the choropleth map\n\np1 <- tm_shape(NGA_wp) +\n  tm_fill(\"wp_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"BuPu\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of functional water point by LGAs\",\n            legend.outside = FALSE)\n\n\np2 <- tm_shape(NGA_wp) +\n  tm_fill(\"total_wp\",\n          n = 10,\n          style = \"equal\",\n          palette = \"BuPu\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of total  water point by LGAs\",\n            legend.outside = FALSE)\n\n\ntmap_arrange(p2, p1, nrow = 1)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07_3.html#mapping-rates-proportions",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07_3.html#mapping-rates-proportions",
    "title": "Analytical Mapping",
    "section": "Mapping Rates (Proportions)",
    "text": "Mapping Rates (Proportions)\n\nFirst, derive the percentages in the table.\n\nNGA_wp <- NGA_wp %>%\n  mutate(pct_functional = wp_functional/total_wp) %>%\n  mutate(pct_nonfunctional = wp_nonfunctional/total_wp)\n\n\nPlot the map:\n\np3 <- tm_shape(NGA_wp) +\n  tm_fill(\"pct_functional\",\n          n = 10,\n          style = \"equal\",\n          palette = \"BuPu\") +\n  tm_borders(lwd = 0.1,\n             alpha = 1) +\n  tm_layout(main.title = \"Distribution of functional water point by LGAs\",\n            legend.outside = TRUE)\n\np3"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex07/In-class_Ex07_3.html#extreme-value-maps",
    "href": "In-class_Ex/In-class_Ex07/In-class_Ex07_3.html#extreme-value-maps",
    "title": "Analytical Mapping",
    "section": "Extreme value maps",
    "text": "Extreme value maps\nThese are variations of common choropleth maps where the classification is designed to highlight extreme values at the lower and upper end of the scale, with the goal of identifying outliers.\n\nPercentile maps\nThe percentile map is a special type of quantile map with six specific categories: 0-1%,1-10%, 10-50%,50-90%,90-99%, and 99-100%. The corresponding breakpoints can be derived by means of the base R quantile command, passing an explicit vector of cumulative probabilities as c(0,.01,.1,.5,.9,.99,1). Note that the begin and endpoint need to be included.\nPrep the data:\n\nNGA_wp <- NGA_wp %>%\n  drop_na()\n\npercent <- c(0,.01,.1,.5,.9,.99,1)\nvar <- NGA_wp[\"pct_functional\"] %>%\n  st_set_geometry(NULL)\nquantile(var[,1], percent)\n\n       0%        1%       10%       50%       90%       99%      100% \n0.0000000 0.0000000 0.2169811 0.4791667 0.8611111 1.0000000 1.0000000 \n\n\n(Note: st_set_geometry(NULL) is used to drop the geometry field so that base r doesn’t struggle with it when extracting variables.)\nCreating the get.var function\n\nget.var <- function(vname,df) {\n  v <- df[vname] %>% \n    st_set_geometry(NULL)\n  v <- unname(v[,1])\n  return(v)\n}\n\n\nA percentile mapping function\n\npercentmap <- function(vnam, df, legtitle=NA, mtitle=\"Percentile Map\"){\n  percent <- c(0,.01,.1,.5,.9,.99,1)\n  var <- get.var(vnam, df)\n  bperc <- quantile(var, percent)\n  tm_shape(df) +\n  tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,\n             title=legtitle,\n             breaks=bperc,\n             palette=\"Blues\",\n          labels=c(\"< 1%\", \"1% - 10%\", \"10% - 50%\", \"50% - 90%\", \"90% - 99%\", \"> 99%\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"right\",\"bottom\"))\n}\n\n\nRun them:\n\npercentmap(\"total_wp\", NGA_wp)\n\n\n\n\n\n\n\n\n\nBox maps\nA box map is an augmented quartile map, with an additional lower and upper category. When there are lower outliers, then the starting point for the breaks is the minimum value, and the second break is the lower fence. In contrast, when there are no lower outliers, then the starting point for the breaks will be the lower fence, and the second break is the minimum value (there will be no observations that fall in the interval between the lower fence and the minimum value).\n\nggplot(data = NGA_wp,\n       aes(x = \"\",\n           y = wp_nonfunctional)) +\n  geom_boxplot()\n\n\n\n\n\nCreating the boxbreaks function\nArguments:\n\nv : vector with observations\nmult : multiplier for inter-quartile range (default is 1.5)\n\nReturns:\n\nbb: vector with 7 break points compute quartile and fences\n\n\n\n\nboxbreaks <- function(v,mult=1.5) {\n  qv <- unname(quantile(v))\n  iqr <- qv[4] - qv[2]\n  upfence <- qv[4] + mult * iqr\n  lofence <- qv[2] - mult * iqr\n  # initialize break points vector\n  bb <- vector(mode=\"numeric\",length=7)\n  # logic for lower and upper fences\n  if (lofence < qv[1]) {  # no lower outliers\n    bb[1] <- lofence\n    bb[2] <- floor(qv[1])\n  } else {\n    bb[2] <- lofence\n    bb[1] <- qv[1]\n  }\n  if (upfence > qv[5]) { # no upper outliers\n    bb[7] <- upfence\n    bb[6] <- ceiling(qv[5])\n  } else {\n    bb[6] <- upfence\n    bb[7] <- qv[5]\n  }\n  bb[3:5] <- qv[2:4]\n  return(bb)\n}\n\n\n\nCreating the get.var function\n\nget.var <- function(vname,df) {\n  v <- df[vname] %>% st_set_geometry(NULL)\n  v <- unname(v[,1])\n  return(v)\n}\n\n\nRun it:\n\nvar <- get.var(\"wp_nonfunctional\", NGA_wp) \nboxbreaks(var)\n\n[1] -56.5   0.0  14.0  34.0  61.0 131.5 278.0\n\n\n\n\nThe Boxmap function\n\nboxmap <- function(vnam, df, \n                   legtitle=NA,\n                   mtitle=\"Box Map\",\n                   mult=1.5){\n  var <- get.var(vnam,df)\n  bb <- boxbreaks(var)\n  tm_shape(df) +\n    tm_polygons() +\n  tm_shape(df) +\n     tm_fill(vnam,title=legtitle,\n             breaks=bb,\n             palette=\"Blues\",\n          labels = c(\"lower outlier\", \n                     \"< 25%\", \n                     \"25% - 50%\", \n                     \"50% - 75%\",\n                     \"> 75%\", \n                     \"upper outlier\"))  +\n  tm_borders() +\n  tm_layout(main.title = mtitle, \n            title.position = c(\"left\",\n                               \"top\"))\n}\n\n\ntmap_mode(\"plot\")\nboxmap(\"wp_nonfunctional\", NGA_wp)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex08/In-class_Ex08.html",
    "href": "In-class_Ex/In-class_Ex08/In-class_Ex08.html",
    "title": "Network Graphing",
    "section": "",
    "text": "Loading packages and importing data\nLoad packages. (We won’t actually be using graphlayouts but good to know it exists.)\n\npacman::p_load(igraph, tidygraph, ggraph, \n               visNetwork, lubridate, clock,\n               tidyverse, graphlayouts)\n\nImport data: two datasets, one corresponding with the nodes and the other corresponding with the edges.\n\nGAStech_nodes <- read_csv(\"data/GAStech_email_node.csv\")\nGAStech_edges <- read_csv(\"data/GAStech_email_edge-v2.csv\")\n\n\n\nData preparation\n#1 Note that although readr was able to identify that the values in the SentTime column were in hours-minutes-seconds (hms) format, it was not able to identify values in the SentDate column as dates. Below, the lubridate package to create a new column SendDate containing the values from SentDate in date format and another new column Weekday containing the corresponding week day.\n\nGAStech_edges <- GAStech_edges %>%\n  mutate(SendDate = dmy(SentDate)) %>%\n  mutate(Weekday = wday(SentDate,\n                        label = TRUE,\n                        abbr = FALSE))\n\n\n#2 To make the dataset more useful for visualisation, we will aggregate the individual by date, senders, receivers, main subject and day of the week. In this case, each edge (connecting two different vertices) is “weighted” by the number of emails between the vertices.\n\nGAStech_edges_aggregated <- GAStech_edges %>%\n  filter(MainSubject == \"Work related\") %>%\n  group_by(source, target, Weekday) %>%\n  summarise(Weight = n()) %>%\n  filter(source!=target) %>%\n  filter(Weight > 1) %>%\n  ungroup()\n\n\n\nCreating Network Objects\n\nGAStech_graph <- tbl_graph(nodes = GAStech_nodes,\n                           edges = GAStech_edges_aggregated, \n                           directed = TRUE)\n\nGAStech_graph\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Node Data: 54 × 4 (active)\n     id label               Department     Title                                \n  <dbl> <chr>               <chr>          <chr>                                \n1     1 Mat.Bramar          Administration Assistant to CEO                     \n2     2 Anda.Ribera         Administration Assistant to CFO                     \n3     3 Rachel.Pantanal     Administration Assistant to CIO                     \n4     4 Linda.Lagos         Administration Assistant to COO                     \n5     5 Ruscella.Mies.Haber Administration Assistant to Engineering Group Manag…\n6     6 Carla.Forluniau     Administration Assistant to IT Group Manager        \n# … with 48 more rows\n#\n# Edge Data: 1,372 × 4\n   from    to Weekday Weight\n  <int> <int> <ord>    <int>\n1     1     2 Sunday       5\n2     1     2 Monday       2\n3     1     2 Tuesday      3\n# … with 1,369 more rows\n\n\n\nFrom the output above, it is seen that the “active” object are the nodes. The code below activates the edges instead, thus R is able to “find” the column Weight, which exists only in the edges table.\n\nGAStech_graph %>%\n  activate(edges) %>%\n  arrange(desc(Weight))\n\n# A tbl_graph: 54 nodes and 1372 edges\n#\n# A directed multigraph with 1 component\n#\n# Edge Data: 1,372 × 4 (active)\n   from    to Weekday  Weight\n  <int> <int> <ord>     <int>\n1    40    41 Saturday     13\n2    41    43 Monday       11\n3    35    31 Tuesday      10\n4    40    41 Monday       10\n5    40    43 Monday       10\n6    36    32 Sunday        9\n# … with 1,366 more rows\n#\n# Node Data: 54 × 4\n     id label           Department     Title           \n  <dbl> <chr>           <chr>          <chr>           \n1     1 Mat.Bramar      Administration Assistant to CEO\n2     2 Anda.Ribera     Administration Assistant to CFO\n3     3 Rachel.Pantanal Administration Assistant to CIO\n# … with 51 more rows\n\n\n\n\nPlotting the Network Graph\nUsing ggraph (an extension of ggplot2). The node is coloured based on Department, and the width of lines (representing edges) will correspond to that edge’s Weight.\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") +\n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 3)\n\ng + theme_graph()\n\n\n\n\n\nUsing it with facet:\n\nset_graph_style()\n\ng <- ggraph(GAStech_graph, \n            layout = \"nicely\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department), \n                  size = 2)\n\ng + facet_edges(~Weekday)\n\n\n\n\n\n\nIncorporating Statistical Measures\n\ng <- GAStech_graph %>%\n  mutate(betweenness_centrality = centrality_betweenness()) %>%  # See note.\n  ggraph(layout = \"fr\") + \n  geom_edge_link(aes(width=Weight), \n                 alpha=0.2) +\n  scale_edge_width(range = c(0.1, 5)) +\n  geom_node_point(aes(colour = Department,\n            size=betweenness_centrality))\ng + theme_graph()\n\n\n\n\n(Note that no new column “betweenness_centrality” is actually appended to the data table. Instead, the outcome of the measurement is passed straight into the object “g” for visualisation.)\n\n\nPreparing data for visNetwork\nPreparing the data model:\n\nGAStech_edges_aggregated <- GAStech_edges %>%\n  left_join(GAStech_nodes, by = c(\"sourceLabel\" = \"label\")) %>%\n  rename(from = id) %>%\n  left_join(GAStech_nodes, by = c(\"targetLabel\" = \"label\")) %>%\n  rename(to = id) %>%\n  filter(MainSubject == \"Work related\") %>%\n  group_by(from, to) %>%\n    summarise(weight = n()) %>%\n  filter(from!=to) %>%\n  filter(weight > 1) %>%\n  ungroup()\n\n\nPlotting the network graph:\n\nGAStech_nodes <- GAStech_nodes %>%\n  rename(group = Department) \n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)\n\n\n\n\n\n\nAdding interactivity (select the node you want - either from a dropdown menu or by clicking directly on the graph - and that node as well as its nearest nodes will be highlighted):\n\nvisNetwork(GAStech_nodes,\n           GAStech_edges_aggregated) %>%\n  visIgraphLayout(layout = \"layout_with_fr\") %>%\n  visOptions(highlightNearest = TRUE,\n             nodesIdSelection = TRUE) %>%\n  visLegend() %>%\n  visLayout(randomSeed = 123)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "Welcome to ISSS608 Visual Analytics and Applications. In this website, you will find my coursework prepared for this course.\nThe coursework is prepared primarily using the R programming language, though Tableau is occasionally used."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Population 1",
    "section": "",
    "text": "In this take-home exercise, we are required to reveal the demographic structure of Singapore at planning area level, using the age-sex pyramid method. We are further required to display nine selected planning areas in a single view, in a trellis display.\nI have chosen to select the 9 most populous planning areas in Singapore.\nData used for this exercise was sourced from the Singapore Department of Statistics, retrieved on 19/1/2023. (Refer to “Singapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2022”)\nThe data visualisation is available here."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#procedures-used-to-prepare-the-data-visualisation",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#procedures-used-to-prepare-the-data-visualisation",
    "title": "Population 1",
    "section": "Procedures used to prepare the data visualisation",
    "text": "Procedures used to prepare the data visualisation\n\n#1. Data Checking\nLooking at the raw data, we see that each row shows the population count for a particular gender and an age group, for a given type of dwelling located in each sub-zone under every planning area. By using the “Describe…” feature for each column, we find all the possible values in each field and note that there are no missing values. We further note the range of values under “Population” is 0 to 2,300, which is entirely plausible. We conclude that no data cleaning is required.\n\n(Note that column headers have been renamed from the original raw data, for ease of understanding.)\n\n\n#2. New columns “Female” and “Male”\nUsing “Create Calculated Field…” in Data Source, I created two new columns, “Female” and “Male”. This will make it easier to model the X-axis later on.\nThe value in each field under “Female” corresponds to the “Population” value for that row, if the value for “Sex” in that row is “Females”. Otherwise, the value is 0. A snapshot of the formula used is shown below. Similarly, the value in each field under “Male” corresponds to the “Population” value for that row, if the value for “Sex” in that row is “Males”. Otherwise, the value is 0.\n\n\n\n#3. Identify top 9 most populous planning areas\nPlotting SUM(Population) by Planning Area, I am able to identify and keep only the top 9 most populous areas, as shown below.\n\n\n\n#4. Column and row indices for trellis display\n(For this step, I relied heavily on this excellent tutorial on creating trellis charts, by Youtuber sqlbelle.)\nWe are able to display the 9 age-sex pyramids in a 3x3 display by setting up column and row indices. There are four steps to doing this:\nStep 1: In a worksheet, under “Data”, create a new calculated field which we can call “Index”. This returns the index for the current row in the partition.\n\nStep 2: Under “Data”, create a parameter called “No_of_Columns”. We give this a current value of 3, an integer, which is the number of columns we would like in our trellis matrix. Creating a parameter makes it easier to adjust how many columns we need in future, in case e.g. we wish to include more planning areas.\n\nStep 3: Create a new calculated field called “Columns”. This will “label” each planning area with a column number 1, 2 or 3, and ensure that each number does not appear more times than the number of rows in our trellis matrix.\n\nStep 4: Then create a new calculated field called “Rows” which will label each planning area with a row number 0, 1 or 2.\n\nFor all three new fields “Index”, “Columns” and “Rows”, I convert the field value to discrete by choosing the appropriate option from the dropdown menu on each field in the Data panel.\nBy dragging “Planning Area” to Columns and dragging both “Columns” and “Rows” to “Text”, I am able to check the assignment of column and row numbers to each planning area. It looks like this:\n\nI note that the planning areas are alphabetically ordered, following the original data set. I will return to this issue later.\n\n\n#5. Create the pyramids\nStep 1: Drag “Planning Area” onto “Colour” on the Marks card. This will automatically distinguish different charts for different planning areas by colour. (There is also a possibility of dragging “Planning Area” onto “Detail”, to set the level of detail at which the charts are to be distinguished, i.e. by planning area. However, I eventually chose against this, and will explain why later.)\nStep 2: Drag “Columns’,”Female” and “Male” to columns. Tableau automatically chooses “SUM(Female)” and “SUM(Male)”. This is what I want so I do not change it. In the drop-down list for “Columns”, I click on “Compute Using” and choose “Planning Area”.\nStep 3: Drag “Rows” and “Age Group” to rows. In the drop-down list for “Rows”, I click on “Compute Using” and choose “Planning Area”.\nStep 4: Since pyramid charts are desired, I need to reverse the bars for the left-hand panes in each planning area’s chart, i.e. the pane showing SUM(Female). I do this by right-clicking on the x-axis for “Female”, choosing “Edit axis” and ticking the check-box next to “Reversed”.\nStep 5: The main issue now is that while the planning areas are distinguished by colour, within each planning area the colours for both Female and Male bars are the same. I am not able to change this (or rather, I do not know how!). However, I am able to change the background colour of the panes. I do this by right-clicking on “Males” in the x-axis, and clicking on “Format”. The Format panel appears on the right, and I click on the “Shading” icon at the top. Under “Column banding”, I am able to choose a new background colour for all “Male” panes. This makes it easier to visually distinguish the “Female” and “Male” bars.\nA few further changes are needed to aid visual analysis:\n\nThe Age-Group labels can be ordered in descending fashion by clicking on the sorting icon next to “Age-Group”. This sorting method puts the age group “5_to_9” between “45_to_49” and “50_to_55”, so I have to manually move it to the correct position.\nI can reorder the planning areas in the trellis in descending order of their respective total population sizes, simply by reordering their positions in the legend at the upper right corner.\nOn the Marks card, for both SUM(Female) and SUM(Male), I click on “Label”, tick the check-box next to “Show mark labels”, click on “Min/Max” and choose only the option of labelling the maximum value. (In all planning areas, it is very clear that the smallest age groups are those 90 and over, hence there is no additional value in labelling these.)\n\n\n\n\nOther comments on procedures\nI note that if I had dragged “Planning Area” to “Detail” instead, the colours for Female and Male bars would be different. This would traditionally be how pyramid charts are presented. However, I encountered two problems. First, I could not figure out how to label each chart with the planning area’s name except manually. Second, I was unable to reorder the charts to show descending order of total population size for each planning area, except by using a new data file which had the planning areas in the desired order. As there were only 9 planning areas of interest, the additional time required to make these changes was not that long, however, it would be very troublesome if the number of planning areas displayed was larger. Hence I opted against this version, shown below.\n\nAnother way to maintain traditional bi-coloured pyramid charts was simply to avoid the creation of a trellis altogether, and have the planning areas lined up in a single row. This format also allowed for easy re-ordering of the planning areas in descending order of total population size. Personally, I also thought it was easier for comparison purposes. Just for interest, this version is also shown, below."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#discussion",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#discussion",
    "title": "Population 1",
    "section": "Discussion",
    "text": "Discussion\nIn general, the widest parts of all pyramids are in the middle, indicating a larger adult and elderly population, and fewer young people. That all 9 planning areas demonstrate this could suggest an overall aging population in Singapore, rather than the possibility that certain planning areas attract more adults and elderly than others.\nThe elderly (65 years and over) as a proportion of total residents is generally the same across all areas. In absolute terms, Bedok, Tampines and Hougang appear to have the largest number of residents who are very elderly (80 years and over). This could have implications for town-planning in terms of accommodating accessibility and mobility (e.g. more lifts and ramps, wider and level footpaths to accommodate mobility aids), and preventing potential hazards (e.g. avoiding shared-use paths), for the elderly. It may also mean that these areas require more public healthcare facilities such as polyclinics, since the elderly are more likely to require healthcare services but are also less likely to be able to afford private healthcare. More geriatric services may also be required.\nIn contrast, young people (up to 14 years) as a proportion of total residents is more variable across areas. For example, this proportion is much larger in Sengkang and Punggol. This also has implications for town-planning in terms of providing more active spaces designed for younger people, as well as the need for a higher concentration of schools.\nIn all areas except Bedok and Jurong West, we see a pattern of widening at two points. The age groups at each of the widest two points are about a generation (30 years) apart. For example, the pyramid for Tampines widens towards the age group 30 – 34 years, and again at 60 – 64 years. The pyramid for Punggol widens towards the age group 5 – 9 years, and again at 35 – 39 years. This could suggest two-generational households forming a majority of residents in these planning areas (adults with their parents in the case of Tampines and young families in the case of Punggol). However, for Bedok and Jurong West, a deeper dive may be needed to see if there is a higher proportion of elderly living alone or with their spouses, as they may require more social care.\nIn general, the numbers of females and males living in each area are fairly balanced. In all planning areas except Woodlands and Choa Chu Kang, the largest age groups for both females and males are either the same or adjacent. In Woodlands and Choa Chu Kang, we note that the largest age group for males is 25 – 29 years (and in the range of 50 – 59 for females). This may be because of male work permit or S Pass holders living in these areas – Woodlands is close to the causeway to Johor Bahru, Malaysia, while there is a large industrial zone in Choa Chu Kang. Assuming the overall global trend that most crime is committed by young males, from a security perspective, these areas may warrant closer observation."
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-Home_Ex02/Take-home_Ex02.html",
    "title": "Population 2",
    "section": "",
    "text": "For this exercise, we have been tasked to critique a data visualisation that has been prepared by one of our peers. We are also to suggest ways it can be improved and show how they can be done.\n\n\n\nA data visualisation prepared by a classmate.\n\n\n\n\nThe title of the Tableau Public page where the data viz above was published, was “Singapore Population Distribution by Age”. Unfortunately, it does not provide any indication of the relevant timeframe, or the source of the data. Their absence reduces the usability and credibility of the viz. Further, it is unclear why the nine specific planning areas were chosen, and thus may be misinterpreted to mean that the nine areas comprise all of Singapore’s population. This would be incorrect.\nA key issue with the chart itself is that values on its y-axis decrease as we move further away from the origin. Although age groups are essentially categorical, it can be confusing for the reader since we are mostly trained to understand that values increase the further away they are from the origin. This may lead to misinterpretation, for example that the youngest age groups are also the smallest.\nThat aside, the viz does give an adequate overall view of how the distribution of age and gender in each planning area compares with the others. The pyramid shapes (once inverted with a correction of the y-axis) can tell a story of an aging population that seems relatively gender-balanced. However, we can explore other ways of visualising the data that might uncover other information.\n\n\n\nThe mark labels on the y-axis are quite cluttered and not easy to read. The bars in each chart appear to vary in intensity, possibly increasing in intensity proportionate to the age group’s population point. This is somewhat redundant since the relative lengths of bars do a much better job visually of conveying magnitude. Unfortunately the varying intensities of colours as a whole does not give a pleasing aesthetic. That said, overall the viz looks clean in that there aren’t many unnecessary elements that might make it difficult to read."
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex02/Take-home_Ex02.html#alternative-design",
    "href": "Take-home_Ex/Take-Home_Ex02/Take-home_Ex02.html#alternative-design",
    "title": "Population 2",
    "section": "Alternative Design",
    "text": "Alternative Design\nHere I will explain how the data viz above might be improved.\n\nLaunch Tidyverse and Import Data\nWe will only be using Tidyverse.\n\npacman::p_load(tidyverse)\npop_data <- read_csv(\"data/respopagesextod2022.csv\")\n\n\n\nPreparing the Data\nAs mentioned previously, it was not clear from the data viz why the nine planning areas shown were selected. However, when we examine the data, we find that they correspond with the top nine planning areas in terms of total resident count, as shown below:\n\npop_data %>%                                        \n  group_by(PA) %>%                      \n  summarise_at(vars(Pop),               \n               list(Total_Residents = sum)) %>%\n  arrange(desc(Total_Residents)) \n\n# A tibble: 55 × 2\n   PA            Total_Residents\n   <chr>                   <dbl>\n 1 Bedok                  278640\n 2 Tampines               265690\n 3 Jurong West            258540\n 4 Sengkang               253120\n 5 Woodlands              252510\n 6 Hougang                227540\n 7 Yishun                 222960\n 8 Choa Chu Kang          190330\n 9 Punggol                186270\n10 Bukit Batok            165160\n# … with 45 more rows\n\n\nWe therefore create a subset of the original dataset with only the nine planning areas we need. We can also take the opportunity here to make changes to the dataset that will increase clarity, namely by ensuring that the planning areas are displayed in descending order of resident count. To do this, we can insert the order number before each planning area name, using mutate() and replace().\n\ntop_nine <- pop_data %>%\n  filter(PA %in% c('Bedok', 'Tampines',  'Jurong West',\n                   'Sengkang', 'Woodlands', 'Hougang',\n                   'Yishun', 'Choa Chu Kang', 'Punggol')) %>%\n  mutate(PA = replace(PA, PA == \"Bedok\", \"1. Bedok\")) %>%\n  mutate(PA = replace(PA, PA == \"Tampines\", \"2. Tampines\")) %>%\n  mutate(PA = replace(PA, PA == \"Jurong West\", \"3. Jurong West\")) %>%\n  mutate(PA = replace(PA, PA == \"Sengkang\", \"4. Sengkang\")) %>%\n  mutate(PA = replace(PA, PA == \"Woodlands\", \"5. Woodlands\")) %>%\n  mutate(PA = replace(PA, PA == \"Hougang\", \"6. Hougang\")) %>%\n  mutate(PA = replace(PA, PA == \"Yishun\", \"7. Yishun\")) %>%\n  mutate(PA = replace(PA, PA == \"Choa Chu Kang\", \"8. Choa Chu Kang\")) %>%\n  mutate(PA = replace(PA, PA == \"Punggol\", \"9. Punggol\")) \n\nWe then select only the columns we want, and group the data so that we have a sub-total count of residents for each age group for each gender.\n\nfinal_data <- top_nine %>%  \n  select(PA, AG, Sex, Pop) %>%\n  group_by(PA, AG, Sex) %>%\n  summarise_at(vars(Pop), list(Count = sum))\n\nTo make the y-axis (i.e. age groups) less cluttered and therefore more readable, we can indicate only the lower limit of each group. We can also convert the values to numeric form, to ensure that the values on the y-axis will increase as they move further away from the origin, thus increasing clarity.\n\nfinal_data <- final_data %>%\n  mutate(AG = replace(AG, AG == \"0_to_4\", 0)) %>%\n  mutate(AG = replace(AG, AG == \"5_to_9\", 5)) %>%\n  mutate(AG = replace(AG, AG == \"10_to_14\", 10)) %>%\n  mutate(AG = replace(AG, AG == \"15_to_19\", 15)) %>%\n  mutate(AG = replace(AG, AG == \"20_to_24\", 20)) %>%\n  mutate(AG = replace(AG, AG == \"25_to_29\", 25)) %>%\n  mutate(AG = replace(AG, AG == \"30_to_34\", 30)) %>%\n  mutate(AG = replace(AG, AG == \"35_to_39\", 35)) %>%\n  mutate(AG = replace(AG, AG == \"40_to_44\", 40)) %>%\n  mutate(AG = replace(AG, AG == \"45_to_49\", 45)) %>%\n  mutate(AG = replace(AG, AG == \"50_to_54\", 50)) %>%\n  mutate(AG = replace(AG, AG == \"55_to_59\", 55)) %>%\n  mutate(AG = replace(AG, AG == \"60_to_64\", 60)) %>%\n  mutate(AG = replace(AG, AG == \"65_to_69\", 65)) %>%\n  mutate(AG = replace(AG, AG == \"70_to_74\", 70)) %>%\n  mutate(AG = replace(AG, AG == \"75_to_79\", 75)) %>%\n  mutate(AG = replace(AG, AG == \"80_to_84\", 80)) %>%\n  mutate(AG = replace(AG, AG == \"85_to_89\", 85)) %>%\n  mutate(AG = replace(AG, AG == \"90_and_over\", 90)) %>%\n  mutate_at(c('AG'), as.numeric)\n\nTo reverse the bars for the male counts, we create another column which has the female count as a positive number and the male count as a negative number.\n\nfinal_data <- final_data %>%\n  group_by(Sex) %>% \n  mutate(Population = ifelse(Sex == \"Females\", Count,-Count))\n\nThen we plot the age-sex pyramids for each planning area, in a trellis display. In doing so, we also add a title which explains the selection of the nine planning areas and the timeframe, as well as a caption mentioning the data’s source. As the default colour options are clear and aesthetically pleasing, we don’t need to further change them.\n\nplotted <- ggplot(final_data, aes(x = AG, Population, fill = Sex)) + \n  geom_bar(data = filter(final_data, Sex == \"Females\"), stat = \"identity\") + \n  geom_bar(data = filter(final_data, Sex == \"Males\"),  stat = \"identity\") + \n  scale_y_continuous(breaks = seq(-10000, 10000, 2500), \n                     labels = abs(seq(-10, 10, 2.5))) +\n  scale_x_continuous(breaks = seq(0, 90, 5)) +\n  coord_flip() +\n  facet_wrap(~ PA) +\n  labs(x = \"Lower Limit of Age Group (years)\", y = \"Resident Count (thousands)\",\n       title = \"Age-Sex Pyramids of 9 Most Populous Planning Areas in Singapore (June 2022)\",\n       caption = \"Data sourced from the Singapore Department of Statistics\") \n\nplotted\n\n\n\n\nWhile the above chart provides a good overview of the relative shapes of the age-sex pyramids, we might be interested to know which age group is the largest for each gender in each planning area.\nTo do this, first we create a new column in the dataset, called “Key”. The value in this column would be the count if the row corresponds with the largest age group for a gender in a planning area. If it is not the largest age group, then the value is simply a character space (i.e. a blank).\n\nfinal_data2 <- final_data %>%\n  group_by(PA, Sex) %>% \n  mutate(Key = ifelse((max(Count) == Count), Count/1000, \" \"))\n\nThen we can label the largest age groups using geom_text(). We also add a caption to explain what each label means.\n\nplotted2 <- ggplot(final_data2, aes(x = AG, Population, fill = Sex)) + \n  geom_bar(data = filter(final_data2, Sex == \"Females\"), stat = \"identity\") + \n  geom_bar(data = filter(final_data2, Sex == \"Males\"),  stat = \"identity\") + \n  geom_text(aes(label=Key)) +\n  scale_y_continuous(breaks = seq(-10000, 10000, 2500), \n                     labels = abs(seq(-10, 10, 2.5))) +\n  scale_x_continuous(breaks = seq(0, 90, 5)) +\n  coord_flip() +\n  facet_wrap(~ PA) +\n  labs(x = \"Lower Limit of Age Group (years)\", y = \"Resident Count (thousands)\",\n       title = \"Age-Sex Pyramids of 9 Most Populous Planning Areas in Singapore (June 2022)\", \n       caption = \"Largest age groups for each gender in each planning area, are indicated with their count.\\n Data sourced from the Singapore Department of Statistics\")\n\nplotted2\n\n\n\n\nWhile this makes it easier to see the values corresponding to each of the largest age groups, perhaps our main interest is to convey anomalies and we are less interested in the detailed values. Instead of labelling the largest age groups with their count values, perhaps we can highlight the corresponding bars instead.\nTo do this, we need to create a new column, similar to what we did before. The difference here is that we then apply it to the chart’s aesthetic fill (i.e. the colours of the bars).\n\nfinal_data3 <- final_data %>%\n  group_by(PA, Sex) %>% \n  mutate(Key = ifelse((max(Count) == Count), \"Largest Age Group\", NA))\n\nplotted3 <- ggplot(final_data3, aes(x = AG, Population, fill = Key)) + \n  geom_bar(data = filter(final_data3, Sex == \"Females\"), stat = \"identity\") + \n  geom_bar(data = filter(final_data3, Sex == \"Males\"),  stat = \"identity\") + \n  scale_y_continuous(breaks = seq(-10000, 10000, 2500), \n                     labels = abs(seq(-10, 10, 2.5))) +\n  scale_x_continuous(breaks = seq(0, 90, 5)) +\n  coord_flip() +\n  facet_wrap(~ PA) +\n  labs(x = \"Lower Limit of Age Group (years)\", y = \"Resident Count (thousands)\",\n       title = \"Largest Age Groups, Male and Female\",\n       caption = \"Male resident count shown to the left of each panel, female to the right.\\n Data sourced from the Singapore Department of Statistics\")\n\nplotted3\n\n\n\n\nWe see from the above a more visually striking contrast between the two planning areas that have a large difference between the largest age groups for the two genders, and the others. However, I was only able to explain that the male resident count is too the left of each panel, and female to the right. I am sure there is a more elegant way that I haven’t figured out yet!"
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex02/Take-home_Ex02.html#conclusion",
    "href": "Take-home_Ex/Take-Home_Ex02/Take-home_Ex02.html#conclusion",
    "title": "Population 2",
    "section": "Conclusion",
    "text": "Conclusion\nWhile there are many ways to change the appearance and content, they should be determined by the message(s) we plan to convey with the data viz. The above are merely some suggestions to improve clarity and aesthetics without adding too much content, and in the absence of the original owner’s intentions. This exercise has also helped me realise the improvements I could have made with my own data viz for Take-home Exercise 1."
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex02/Take-home_Ex02.html#extra",
    "href": "Take-home_Ex/Take-Home_Ex02/Take-home_Ex02.html#extra",
    "title": "Population 2",
    "section": "Extra",
    "text": "Extra\nThe following was added after the deadline for this exercise. We were asked in class to consider displaying the pyramids in a manner that would allow direct contrast with the age-sex pyramid shape for the total population of Singapore.\nThe first few steps are very similar to what I did before:\n\nTop_Nine <- top_nine %>%\n  group_by(PA, AG, Sex) %>%\n  summarise(Count = sum(Pop)) %>%\n  group_by(PA) %>%\n  mutate(percentofPA = (Count/sum(Count))*100) %>%\n  select(PA, AG, Sex, percentofPA)\n\n\nSingapore <- pop_data %>%\n  group_by(AG, Sex) %>%\n  summarise(Count = sum(Pop)) %>%\n  ungroup(AG, Sex) %>%\n  mutate(percentofSG = (Count/sum(Count))*100)\n\n\nFinal <- left_join(Top_Nine, Singapore, by = c('AG'='AG', 'Sex'='Sex'))\n\n\nFinal1 <- Final %>%\n  mutate(AG = replace(AG, AG == \"0_to_4\", 0)) %>%\n  mutate(AG = replace(AG, AG == \"5_to_9\", 5)) %>%\n  mutate(AG = replace(AG, AG == \"10_to_14\", 10)) %>%\n  mutate(AG = replace(AG, AG == \"15_to_19\", 15)) %>%\n  mutate(AG = replace(AG, AG == \"20_to_24\", 20)) %>%\n  mutate(AG = replace(AG, AG == \"25_to_29\", 25)) %>%\n  mutate(AG = replace(AG, AG == \"30_to_34\", 30)) %>%\n  mutate(AG = replace(AG, AG == \"35_to_39\", 35)) %>%\n  mutate(AG = replace(AG, AG == \"40_to_44\", 40)) %>%\n  mutate(AG = replace(AG, AG == \"45_to_49\", 45)) %>%\n  mutate(AG = replace(AG, AG == \"50_to_54\", 50)) %>%\n  mutate(AG = replace(AG, AG == \"55_to_59\", 55)) %>%\n  mutate(AG = replace(AG, AG == \"60_to_64\", 60)) %>%\n  mutate(AG = replace(AG, AG == \"65_to_69\", 65)) %>%\n  mutate(AG = replace(AG, AG == \"70_to_74\", 70)) %>%\n  mutate(AG = replace(AG, AG == \"75_to_79\", 75)) %>%\n  mutate(AG = replace(AG, AG == \"80_to_84\", 80)) %>%\n  mutate(AG = replace(AG, AG == \"85_to_89\", 85)) %>%\n  mutate(AG = replace(AG, AG == \"90_and_over\", 90)) %>%\n  mutate_at(c('AG'), as.numeric)\n\nWhen visualising two population pyramids overlapping each other, with each pyramid a “translucent” colour, we would ultimately see three colours. Assuming the planning area’s population pyramid is pink and the Singapore population pyramid is grey, then the areas of overlap would appear a greyish-pink. Where the planning area population exceeds the Singapore population, it would appear pink. Conversely, where the Singapore population exceeds the planning area population, it would appear grey.\nIn effect, there are four parts to each bar in the pyramid chart (although in each case, only two parts have values >0):\n\nThe planning area population percentage, where the Singapore population percentage for an age group exceeds that of the planning area. This appears as greyish-pink.\nIn relation to the above, the Singapore percentage in excess of the planning area percentage. This appears as grey.\nThe Singapore population percentage, where the planning area population percentage for an age group exceeds that of Singapore. This appears as greyish-pink.\nIn relation to the above, the planning area percentage in excess of the Singapore percentage. This appears as pink.\n\nNote that I also used percentages instead of absolute count, for better comparison.\n\nFinal6 <- Final1 %>%\n  select(PA, AG, Sex, percentofPA, percentofSG) %>%\n  mutate(Category = \"A\") %>%\n  mutate(PerCent = ifelse(percentofPA<=percentofSG, (percentofSG - percentofPA), 0)) %>%\n  group_by(PA, AG, Sex, percentofPA, percentofSG) %>%\n  group_modify(~ add_row(., Category = \"B\")) %>%\n  group_modify(~ add_row(., Category = \"C\")) %>%\n  group_modify(~ add_row(., Category = \"D\")) %>%\n  mutate(PerCent = ifelse(Category == \"B\" & percentofPA>percentofSG, (percentofPA - percentofSG), PerCent)) %>%\n  mutate(PerCent = ifelse(Category == \"C\" & percentofSG<percentofPA, percentofSG, PerCent)) %>%\n  mutate(PerCent = ifelse(Category == \"D\" & percentofSG>=percentofPA, percentofPA, PerCent)) %>%\n  replace(is.na(.), 0) %>% \n  mutate(PerCent = ifelse(Sex == \"Females\", PerCent,-PerCent))\n\n\nplotted2 <- ggplot(Final6, aes(x = AG, PerCent, fill = Sex)) + \n  geom_bar(data = filter(Final6, Sex == \"Females\"), stat = \"identity\", aes(fill = Category)) + \n  geom_bar(data = filter(Final6, Sex == \"Males\"),  stat = \"identity\", aes(fill = Category)) + \n  scale_fill_manual(values = c('gray70', 'rosybrown1', 'rosybrown', 'rosybrown')) + \n  coord_flip() +\n  scale_y_continuous(breaks = seq(-5, 5, 2.5), \n                     labels = abs(seq(-5, 5, 2.5))) +\n  scale_x_continuous(breaks = seq(0, 90, 5)) + \n  facet_wrap(~ PA) +\n  theme(legend.position=\"none\") +\n  labs(x = \"Lower Limit of Age Group (years)\", y = \"Resident Count (%)\",\n       title = \"Age-Sex Pyramids of 9 Most Populous Planning Areas in Singapore (June 2022)\", \n       subtitle = \"Compared to Total Singapore Age-Sex Distribution\", \n       caption = \"Data sourced from the Singapore Department of Statistics\\n Planning Area pyramid shown as translucent pink, Singapore pyramid shown as translucent gray\") \n\nplotted2"
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-Home_Ex03/Take-home_Ex03.html",
    "title": "Resale Prices",
    "section": "",
    "text": "In this exercise, we are tasked with statistical analysis, prediction and data visualisations using a dataset of HDB resale prices for sales registered since 1 January 2017 (source: Data.gov.sg)."
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex03/Take-home_Ex03.html#loading-packages-and-importing-dataset",
    "href": "Take-home_Ex/Take-Home_Ex03/Take-home_Ex03.html#loading-packages-and-importing-dataset",
    "title": "Resale Prices",
    "section": "Loading packages and importing dataset",
    "text": "Loading packages and importing dataset\n\npacman::p_load(ggstatsplot, performance, ggiraph, plotly, FunnelPlotR, tidyverse, patchwork)\n\n\nresale_data <- read_csv(\"data/resale-flat-prices-based-on-registration-date-from-jan-2017-onwards.csv\")\n\nAs the assignment requires us to focus our study on the time period 2022 and the flat types “3-ROOM”, “4-ROOM” and “5-ROOM”, we can filter the required data as follows:\n\nresale_data2022 <- resale_data %>%\n  filter(grepl(\"2022\", month), flat_type == \"3 ROOM\" | flat_type == \"4 ROOM\" | flat_type == \"5 ROOM\")"
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex03/Take-home_Ex03.html#resale-prices-by-flat-type",
    "href": "Take-home_Ex/Take-Home_Ex03/Take-home_Ex03.html#resale-prices-by-flat-type",
    "title": "Resale Prices",
    "section": "1. Resale prices by flat type",
    "text": "1. Resale prices by flat type\n\nDescription:\nWe wish to compare resale prices by flat-type. Since it is expected that resale prices would be higher for larger flats (assuming “larger” refers to number of rooms, therefore e.g. 5-room flats are more expensive than 4-room flats), we will instead use price per square foot (psf) as our measure. Price psf is often used in the property sector.\nA common assumption is that larger units would have lower price psf. We can investigate if this is true, while examining the means and distributions of prices psf for each flat-type. We first compute price psf (using 1 sqm = 10.764 sqft), then use ggbetweenstats() to conduct a One-way ANOVA test on price psf by flat-type.\n\nresale_data2022_psf <- resale_data2022 %>%\n  mutate(RPpsf = (resale_price/floor_area_sqm)/10.764)   \n\n\nggbetweenstats(\n  data = resale_data2022_psf,\n  x = flat_type, \n  y = RPpsf,\n  type = \"p\",\n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  messages = FALSE,\n  xlab = \"Flat Type\",\n  ylab = \"Price per Square Foot\",\n  title = \"One-way ANOVA test on Price per square foot by flat type\",\n  subtitle = \"Resale prices for 3, 4 and 5-room HDB flats in 2022\"\n  ## Note that we can go along with default method (\"holm\") for p-value adjustment\n)\n\n\n\n\n\nPatterns revealed:\nFirst, we note that the differences between the mean prices psf of the three flat-types are statistically significant at the 95% confidence level. Second, we see that the mean price psf for 4-room flats is higher than that for 3-room flats, going against the usual assumption. However, it is also observed that the distance between mean and median, as well as the distance between the median and the maximum value (excluding outliers), are much higher for 4-room flats compared to the other two flat-types. There is more variance at the upper end of prices psf for 4-room flats."
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex03/Take-home_Ex03.html#correlation-between-resale-price-and-remaining-lease",
    "href": "Take-home_Ex/Take-Home_Ex03/Take-home_Ex03.html#correlation-between-resale-price-and-remaining-lease",
    "title": "Resale Prices",
    "section": "2. Correlation between Resale Price and Remaining Lease",
    "text": "2. Correlation between Resale Price and Remaining Lease\nDescription:\nIt is expected that the remaining lease on a flat would influence its resale price. We’re interested to find out if there is a difference in the strengths of the correlations across the three flat-types. To visualise this, we use ggscatterstats(). In addition, we can investigate whether remaining lease is independent of or associated with flat-type, using ggbarstats(). We can display these charts in a 2x2 grid using the patchwork package.\nHowever, before using either, we need to convert the remaining lease values to numeric data. From examining the data, we note that remaining lease ranges from 43 to 96 years, when rounded down to the nearest year. We use mutate() and substr() to extract the number of years to a new column.\n\nresale_data2022_yy <- resale_data2022 %>%\n  mutate(rl_yy = as.numeric(substr(remaining_lease, start=1, stop=2)))\n\n\n# Scatterplots with marginal distributions and statistical results,\n# for remaining lease and resale price, three flat types.\n\np1 <- ggscatterstats(\n  data = filter(.data=resale_data2022_yy, flat_type == \"3 ROOM\"),\n  x = rl_yy,\n  y = resale_price,\n  xlab = \"Remaining Lease (years)\",\n  ylab = \"Resale Price (thousands)\",\n  title = \"3 ROOM\"\n) +\n  scale_y_continuous(breaks = seq(100000, 1500000, 200000),\n                     labels = seq(100, 1500, 200))\n\np2 <- ggscatterstats(\n  data = filter(.data=resale_data2022_yy, flat_type == \"4 ROOM\"),\n  x = rl_yy,\n  y = resale_price,\n  xlab = \"Remaining Lease (years)\",\n  ylab = \"Resale Price (thousands)\",\n  title = \"4 ROOM\"\n) +\n  scale_y_continuous(breaks = seq(100000, 1500000, 200000),\n                     labels = seq(100, 1500, 200))\n\np3 <- ggscatterstats(\n  data = filter(.data=resale_data2022_yy, flat_type == \"5 ROOM\"),\n  x = rl_yy,\n  y = resale_price,\n  xlab = \"Remaining Lease (years)\",\n  ylab = \"Resale Price (thousands)\",\n  title = \"5 ROOM\"\n) +\n  scale_y_continuous(breaks = seq(100000, 1500000, 200000),\n                     labels = seq(100, 1500, 200))\n\n## Stacked bar charts with statistical tests,\n## for test of association between flat type and remaining lease\n\nresale_data2022_yy1 <- resale_data2022_yy %>% \n  mutate(rl_yy_bins = cut(rl_yy, breaks = c(0,55,70,85,100))\n)\n\np4 <- ggbarstats(resale_data2022_yy1, \n           x = rl_yy_bins, \n           y = flat_type,\n           title = \"Significance Test of Association\",\n           legend.title = \"Remaining Lease Bins\",\n           xlab = \"Flat Type\")\n\np1 + p2 + p3 + p4\n\n\n\n\n\nPatterns revealed:\nThere is significant linear relationship between remaining lease and resale price for all three flat-types. The Pearson’s correlation coefficient shows positive relationship for all three flat-types, and is strongest for 3-room flats while weakest for 5-room flats. We are also able to observe this from the scatterplots, which show greatest distribution of points for 5-room flats. The marginal distributions for each flat-type indicate that while resale prices are somewhat normally distributed, remaining lease years are not. The latter is reflected in the stacked bar charts and test results, which show significant association between flat-type and remaining lease."
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex03/Take-home_Ex03.html#regression-model-for-resale-price",
    "href": "Take-home_Ex/Take-Home_Ex03/Take-home_Ex03.html#regression-model-for-resale-price",
    "title": "Resale Prices",
    "section": "3. Regression model for Resale Price",
    "text": "3. Regression model for Resale Price\nDescription:\nWe would like to be able to predict resale price based on a flat’s characteristics, by building a regression model using lm(). We will use number of rooms, storey range, floor area and remaining lease. As there are currently 17 categories in storey range, we will reduce it to five categories by creating a category for 13th storey and above. Then we will convert the desired character columns to factors, so that R automatically treats those variables as reference dummies when running the regression.\nWe will also use check_model() to check that the model satisfies the assumptions for a multiple linear regression model.\nAlthough address (town, street name and block) is expected to affect resale price, there would be too many addresses with too few observations each, hence we exclude it from the model. Flat model is also omitted as the metadata does not include an explanation for this variable.\n\nfor_regression <- resale_data2022_yy %>%\n  mutate(start_range = if_else(\n    storey_range == \"01 TO 03\" | \n      storey_range == \"04 TO 06\" | \n      storey_range == \"07 TO 09\" | \n      storey_range == \"10 TO 12\", storey_range, \"13 OR MORE\")) %>%\n  mutate_at(c(\"flat_type\", \"start_range\"), as.factor)\n\n\nrp_model <- lm(resale_price ~ flat_type + start_range + \n              floor_area_sqm + rl_yy, data = for_regression)\n\n\ncheck_model(rp_model)\n\n\n\n\n\nrp_model1 <- lm(resale_price ~ start_range + \n              floor_area_sqm + rl_yy, data = for_regression)\n\nsummary(rp_model1)\n\n\nCall:\nlm(formula = resale_price ~ start_range + floor_area_sqm + rl_yy, \n    data = for_regression)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-265726  -64778  -19495   35269  715432 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(>|t|)    \n(Intercept)           -135848.89    4568.41 -29.737   <2e-16 ***\nstart_range04 TO 06     19395.70    2179.50   8.899   <2e-16 ***\nstart_range07 TO 09     35285.45    2211.63  15.954   <2e-16 ***\nstart_range10 TO 12     42229.18    2281.88  18.506   <2e-16 ***\nstart_range13 OR MORE  129110.46    2273.17  56.798   <2e-16 ***\nfloor_area_sqm           4176.22      35.69 117.005   <2e-16 ***\nrl_yy                    3136.99      47.90  65.497   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 105500 on 24365 degrees of freedom\nMultiple R-squared:  0.5542,    Adjusted R-squared:  0.554 \nF-statistic:  5047 on 6 and 24365 DF,  p-value: < 2.2e-16\n\n\n\nPatterns revealed:\nAs there was high collinearity observed between flat type and floor area in the first regression model, we ran another regression model which excluded flat type. The results show significant linear relationships between each independent variable and resale price, at 95% confidence level. It is observed that flats on higher storeys command higher resale prices, all other variables kept equal. The large coefficients for floor area and remaining lease years also show strong influence on resale price. However, adjusted R-squared indicates this model explains only 55% of variability, suggesting that there are other factors to consider when predicting resale price."
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex03/Take-home_Ex03.html#uncertainty-in-mean-resale-price",
    "href": "Take-home_Ex/Take-Home_Ex03/Take-home_Ex03.html#uncertainty-in-mean-resale-price",
    "title": "Resale Prices",
    "section": "4. Uncertainty in mean Resale Price",
    "text": "4. Uncertainty in mean Resale Price\nDescription:\nWe would like to visualise the uncertainty of point estimates with regard to mean resale prices by flat type. We can do this using geom_errorbar() with interactive mean points which show the 95% confidence interval. However, first we need to group observations and tabulate count, mean, standard deviation and standard error for each group.\n\nmy_sum <- resale_data2022 %>%\n  group_by(flat_type) %>%\n  summarise(\n    n = n(),\n    mean = mean(resale_price),\n    sd = sd(resale_price)\n  ) %>%\n  mutate(se = sd/sqrt(n-1))\n\nmy_sum\n\n# A tibble: 3 × 5\n  flat_type     n    mean      sd    se\n  <chr>     <int>   <dbl>   <dbl> <dbl>\n1 3 ROOM     6345 388904.  85288. 1071.\n2 4 ROOM    11311 549079. 129347. 1216.\n3 5 ROOM     6716 654373. 144236. 1760.\n\n\n\ntcrit <- qnorm(0.025)\n\nmy_sum$tooltip <- c(paste0(\n  \"Flat type = \", my_sum$flat_type,\n  \"\\n N = \", my_sum$n,\n  \"\\n Avg. Resale Price = \", as.integer(my_sum$mean),\n  \"\\n 95% CI: [\", as.integer(my_sum$mean+(tcrit*my_sum$se)), \" , \", as.integer(my_sum$mean-(tcrit*my_sum$se)), \"]\"\n))\n\np <- ggplot(my_sum) +\n  geom_errorbar(\n    aes(x = reorder(flat_type, -mean), ymin = mean+(tcrit*se), ymax = mean-(tcrit*se)),\n    width = 0.2, colour = \"black\", alpha = 0.9, size = 0.5) +\n  scale_y_continuous(breaks = seq(400000, 700000, 50000),\n                     labels = seq(400, 700, 50)) +\n  geom_point_interactive(\n    aes(x = reorder(flat_type, -mean), y = mean, tooltip = my_sum$tooltip), \n    stat = \"identity\", colour = \"red\", size = 1.5, alpha = 1) +\n  ggtitle(\"Standard error of mean resale price by flat type\") +\n  labs(x = \"Flat Type\", y = \"Resale Price (thousands)\")\n\ngirafe(ggobj = p,\n       width_svg = 8,\n       height_svg = 8*0.618\n)\n\n\n\n\n\n\nPatterns revealed:\nThe above shows that the mean resale price for 5-room flats has the widest 95% confidence interval. (Given the differences in mean resale price for the three flat types and the constraints of the plot, it is a bit difficult to see the exact values in each confidence interval. However the interactive mean points display these clearly for the reader.)"
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex03/Take-home_Ex03.html#x.-street-performance-resale-prices-that-exceed-predicted",
    "href": "Take-home_Ex/Take-Home_Ex03/Take-home_Ex03.html#x.-street-performance-resale-prices-that-exceed-predicted",
    "title": "Resale Prices",
    "section": "X. Street performance (resale prices that exceed predicted)",
    "text": "X. Street performance (resale prices that exceed predicted)\nDescription:\nLet’s say we wish to compare the performance of different towns or different streets in Singapore, where performance is measured by whether a street’s HDB resale prices have exceeded expectations. The expected resale price is predicted by our earlier regression model (rp_model1). Perhaps we could visualise this on a funnel plot, using funnel_plot().\nFirst, I have created a new column containing the predicted resale prices, by using the intercept and coefficients from rp_model1. This is to allow me to obtain, for each town, the number of sales which resale prices exceeded expectations.\n\nresale_data2022_prd <- for_regression %>%\n  mutate(predicted = -135849 +\n           (19396*ifelse(flat_type == \"04 TO 06\", 1, 0)) +\n           (35285*ifelse(flat_type == \"07 TO 09\", 1, 0)) +\n           (42229*ifelse(flat_type == \"10 TO 12\", 1, 0)) +\n           (129110*ifelse(flat_type == \"13 OR MORE\", 1, 0) +\n              (4176*floor_area_sqm) +\n              (3137*rl_yy)))\n\nFirst, trying out the funnel plot with town as group.\n\nfor_funnelplot <- resale_data2022_prd %>%\n  mutate(exceeded = ifelse(resale_price > predicted, 1, 0)) %>%\n  group_by(town) %>%\n  summarise(total_exceeded = sum(exceeded), n = n())\n\n\nfunnel_plot(\n  numerator = for_funnelplot$total_exceeded,\n  denominator = for_funnelplot$n,\n  group = for_funnelplot$town,\n  data_type = \"PR\",\n  title = \"Cumulative Rate of Resale Prices Exceeding Predicted by\\n Cumulative Resale Transactions\",\n  x_label = \"Cumulative Resale Transactions\",\n  y_label = \"Cumulative Rate of Resale Prices\\n Exceeding Predicted\"\n)\n\n\n\n\nA funnel plot object with 26 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\nThis looks odd. Next, try funnel plot with street as group.\n\nfor_funnelplot1 <- resale_data2022_prd %>%\n  mutate(exceeded = ifelse(resale_price > predicted, 1, 0)) %>%\n  group_by(street_name) %>%\n  summarise(total_exceeded = sum(exceeded), n = n())\n\n\nfunnel_plot(\n  numerator = for_funnelplot1$total_exceeded,\n  denominator = for_funnelplot1$n,\n  group = for_funnelplot1$street_name,\n  data_type = \"PR\",\n  title = \"Cumulative Rate of Resale Prices Exceeding Predicted by\\n Cumulative Resale Transactions\",\n  x_label = \"Cumulative Resale Transactions\",\n  y_label = \"Cumulative Rate of Resale Prices\\n Exceeding Predicted\"\n)\n\n\n\n\nA funnel plot object with 552 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\nThis plot also looks odd - nothing like a funnel. Perhaps it is because the measures of variation are not well-developed enough. According to this paper by the Canadian Institute for Health Information, funnel plots only work for indicators with well-developed measures of variation. Unfortunately no patterns to reveal here!"
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex04/Take-home_Ex04.html",
    "href": "Take-home_Ex/Take-Home_Ex04/Take-home_Ex04.html",
    "title": "Trade Trends",
    "section": "",
    "text": "I will attempt to visualise how the main world events of this period - the COVID-19 pandemic and Russia’s military actions in Ukraine - impacted merchandise trade with Singapore.\nFor this exercise, I will use monthly data on merchandise trade volumes with economies that Singapore imports from or exports to, from January 2020 to December 2022 inclusive. Trade volumes are shown as values, in Singapore dollars. The data is the Singapore Department of Statistics and the dataset is available here."
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex04/Take-home_Ex04.html#line-charts-with-ggbraid",
    "href": "Take-home_Ex/Take-Home_Ex04/Take-home_Ex04.html#line-charts-with-ggbraid",
    "title": "Trade Trends",
    "section": "Line charts with ggbraid()",
    "text": "Line charts with ggbraid()\nI will plot the trade balances for the top 20 countries, in descending order of total trade value in 2022. To keep this short, only the code chunks for the first 5 plots will be shown initially, but all 20 charts will be displayed in a grid later on.\nFor each chart, the import and export values for each month will be plotted as lines. I will then use the ggplot2 extension ggbraid to fill the gap between the lines, with different colours indicating trade surpluses and trade deficits.\n\n\n\nChinaMalaysiaUnited StatesTaiwanHong Kong\n\n\n\nChina_wide <- trade_data %>%\n  filter(Economy == \"Mainland China\")\n\nChina_long <- China_wide %>%\n  gather(key = \"Type\", value = \"Value\", 3:4)\n\np1 <- ggplot(data=China_long, aes(Date)) +\n  geom_line(aes(y=Value, linetype=Type)) +\n  geom_braid(data=China_wide, aes(ymin=Imports, ymax=Exports, \n                                  fill=after_stat(braid)), alpha=0.6,\n             show.legend=FALSE) +\n  labs(title=\"1. Mainland China\") +\n  xlab(\"Month - Year\") +\n  ylab(\"Volume (millions)\") +\n  scale_y_continuous(breaks=seq(4000000,9000000,1000000),\n                     labels=seq(4000,9000,1000))\np1\n\n\n\n\n\n\n\nMalaysia_wide <- trade_data %>%\n  filter(Economy == \"Malaysia\")\n\nMalaysia_long <- Malaysia_wide %>%\n  gather(key = \"Type\", value = \"Value\", 3:4)\n\np2 <- ggplot(data=Malaysia_long, aes(Date)) +\n  geom_line(aes(y=Value, linetype=Type)) +\n  geom_braid(data=Malaysia_wide, aes(ymin=Imports, ymax=Exports, \n                                  fill=after_stat(braid)), alpha=0.6,\n             show.legend=FALSE) +\n  labs(title=\"2. Malaysia\") +\n  xlab(\"Month - Year\") +\n  ylab(\"Volume (millions)\") +\n  scale_y_continuous(breaks=seq(3000000,8000000,1000000),\n                     labels=seq(3000,8000,1000))\np2\n\n\n\n\n\n\n\nUS_wide <- trade_data %>%\n  filter(Economy == \"United States\")\n\nUS_long <- US_wide %>%\n  gather(key = \"Type\", value = \"Value\", 3:4)\n\np3 <- ggplot(data=US_long, aes(Date)) +\n  geom_line(aes(y=Value, linetype=Type)) +\n  geom_braid(data=US_wide, aes(ymin=Imports, ymax=Exports, \n                                  fill=after_stat(braid)), alpha=0.6,\n             show.legend=FALSE) +\n  labs(title=\"3. United States\") +\n  xlab(\"Month - Year\") +\n  ylab(\"Volume (millions)\") +\n  scale_y_continuous(breaks=seq(4000000,7000000,1000000),\n                     labels=seq(4000,7000,1000))\np3\n\n\n\n\n\n\n\nTaiwan_wide <- trade_data %>%\n  filter(Economy == \"Taiwan\")\n\nTaiwan_long <- Taiwan_wide %>%\n  gather(key = \"Type\", value = \"Value\", 3:4)\n\np4 <- ggplot(data=Taiwan_long, aes(Date)) +\n  geom_line(aes(y=Value, linetype=Type)) +\n  geom_braid(data=Taiwan_wide, aes(ymin=Imports, ymax=Exports, \n                                  fill=after_stat(braid)), alpha=0.6,\n             show.legend=FALSE) +\n  labs(title=\"4. Taiwan\") +\n  xlab(\"Month - Year\") +\n  ylab(\"Volume (millions)\") +\n  scale_y_continuous(breaks=seq(2000000,7000000,1000000),\n                     labels=seq(2000,7000,1000))\np4\n\n\n\n\n\n\nFor Hong Kong, I encountered the problem that although there was a persistent trade surplus over the period of interest, the ribbon (area between the export and import lines) was automatically coloured peach (#F8766D). In previous charts, surpluses were coloured cyan (#00BFC4) and deficits peach. To resolve this issue, I manually reversed the colour options using scale_fill_manual(), to ensure consistency in the visualisation. (The same problem was encountered with other charts showing persistent surplus, and the same resolution applied.)\n\nHK_wide <- trade_data %>%\n  filter(Economy == \"Hong Kong\")\n\nHK_long <- HK_wide %>%\n  gather(key = \"Type\", value = \"Value\", 3:4)\n\np5 <- ggplot(data=HK_long, aes(Date)) +\n  geom_line(aes(y=Value, linetype=Type)) +\n  geom_braid(data=HK_wide, aes(ymin=Imports, ymax=Exports, \n                                  fill=after_stat(braid)), alpha=0.6,\n             show.legend=FALSE) +\n  scale_fill_manual(values=c(\"#00BFC4\", \"#F8766D\"), name=\"fill\") +\n  labs(title=\"5. Hong Kong\") +\n  xlab(\"Month - Year\") +\n  ylab(\"Volume (millions)\") +\n  scale_y_continuous(breaks=seq(1000000,8000000,1000000),\n                     labels=seq(1000,8000,1000))\np5\n\n\n\n\n\n\n\n\nThe code chunk below arranges all 20 plots in a grid fashion with two columns and a main title.\n\nPlotsList<- list(p1,p2,p3,p4,p5,p6,p7,p8,p9,p10,\n                 p11,p12,p13,p14,p15,p16,p17,p18,p19,p20)\ngrid.arrange(grobs = PlotsList, ncol = 2, \n             top = textGrob(\"Trade Balances from 2020 to 2022 with top 20 economies (in terms of total trade value in 2022)\\n\",gp=gpar(fontsize=12,font=3)))\n\n\n\n\n\nPatterns revealed:\nFor all economies, there was a pronounced dip in trade at about the end of the first quarter of 2020. This corresponds with the start of health and safety measures being implemented around the world in response to the COVID-19 pandemic, leading to diminished operations or even full closures of some ports and factories.\nThese closures likely resulted in the period of trade surpluses with China, starting in the first quarter of 2020 and ending in the third quarter of 2022. A similar but less pronounced effect can be observed in trade with the United States, Japan and the Republic of Korea. Spikes showing sudden and short-lived changes in the trade balance can be observed for other economies too, and these may be attributed to lockdowns that abruptly but temporarily restricted imports or exports.\nAlthough trade gradually recovered with the lifting of pandemic measures through 2021 and into early 2022, the impact of Russia’s military actions in Ukraine which began in February 2022 is shown in the start of a plateau or downward trend in trade for all economies thereafter."
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex04/Take-home_Ex04.html#line-charts-with-same-axes-scales",
    "href": "Take-home_Ex/Take-Home_Ex04/Take-home_Ex04.html#line-charts-with-same-axes-scales",
    "title": "Trade Trends",
    "section": "Line charts with same axes scales",
    "text": "Line charts with same axes scales\nWhile the line charts of the previous section provided an overall sense of trade and trade balance with individual economies, they are not directly comparable because different scales were used for their axes. This was unavoidable given the large difference in trade volumes between the economies. Maintaining the same scale across all charts would have sacrificed visibility of those with smaller trade volumes.\nSimple line charts allow for direct comparison. However, with 20 economies, visibility is still an issue as economies with large volumes will appear at the top of the plot and those with smaller volumes (the majority of economies in the top 20) would cluster at the bottom. I will focus on the top 10 trading partners, in two parts.\n\n\n\nCodeTop 5 (Imports)Top 5 (Exports)Rest (Imports)Rest (Exports)\n\n\nPreparing data and plotting charts for top 10 trading partners:\n\n\ntrade_data2 <- trade_data %>%\n  filter(Economy==\"Mainland China\" | Economy==\"Malaysia\" | \n           Economy==\"United States\"| Economy==\"Taiwan\" | Economy==\"Hong Kong\") %>%\n  mutate(Economy = if_else(Economy==\"Mainland China\", \"China\", Economy)) %>%\n  select(Economy, Date, Imports, Exports)\n\np21 <- ggplot(data=trade_data2, aes(x=Date, y=Imports, color=Economy)) +\n  geom_line() +\n  ggtitle(\"Top 5 economies: Imports\") +\n  labs(x=\"Month-Year\", y=\"Trade Volumes in SGD millions\") +\n  scale_x_date(breaks=\"3 months\") +\n  scale_y_continuous(breaks=seq(0,8000000,2000000),\n                     labels=seq(0,8000,2000)) +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))\n\np22 <- ggplot(data=trade_data2, aes(x=Date, y=Exports, color=Economy)) +\n  geom_line() +\n  ggtitle(\"Top 5 economies: Exports\") +\n  labs(x=\"Month-Year\", y=\"Trade Volumes in SGD millions\") +\n  scale_x_date(breaks=\"3 months\") +\n  scale_y_continuous(breaks=seq(0,8000000,2000000),\n                     labels=seq(0,8000,2000)) +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5))\n\ntrade_data3 <- trade_data %>%\n  filter(Economy==\"Indonesia\" | Economy==\"Republic Of Korea\" |\n           Economy==\"Japan\" | Economy==\"Thailand\" | Economy==\"Australia\") %>%\n  mutate(Economy = if_else(Economy==\"Republic Of Korea\", \"South Korea\",\n                           Economy))  %>%\n  select(Economy, Date, Imports, Exports)\n\np23 <- ggplot(data=trade_data3, aes(x=Date, y=Imports, color=Economy)) +\n  geom_line() +\n  ggtitle(\"Other economies in top 10: Imports\") +\n  labs(x=\"Month-Year\", y=\"Trade Volumes in SGD millions\") +\n  scale_x_date(breaks=\"3 months\") +\n  scale_y_continuous(breaks=seq(0,8000000,2000000),\n                     labels=seq(0,8000,2000)) +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5)) +\n  scale_color_brewer(palette = \"Dark2\")\n\np24 <- ggplot(data=trade_data3, aes(x=Date, y=Exports, color=Economy)) +\n  geom_line() +\n  ggtitle(\"Other economies in top 10: Exports\") +\n  labs(x=\"Month-Year\", y=\"Trade Volumes in SGD millions\") +\n  scale_x_date(breaks=\"3 months\") +\n  scale_y_continuous(breaks=seq(0,8000000,2000000),\n                     labels=seq(0,8000,2000)) +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5)) +\n  scale_color_brewer(palette = \"Dark2\")\n\n\n\n\np21\n\n\n\n\n\n\n\np22\n\n\n\n\n\n\n\np23\n\n\n\n\n\n\n\np24\n\n\n\n\n\n\n\n\n\nPatterns revealed:\nThe top 4 trading partners are clustered together in terms of import volumes, separated from the fifth largest trading partner by about $2.5 billion (start of pandemic) to $6 billion (two years later) in monthly trade volumes. Differences in export volumes are less pronounced and more even, with China clearly the largest trading partner despite the pandemic. The relative sizes of trading volumes amongst the remaining economies in the top 10 are fairly consistent except in the case of exports to Indonesia, which started to pull away from the other economies from mid-2020, during the period of study. (A longer timeframe might provide more insight whether this reflects an upward trend for exports to Indonesia, or a combination of trends for other economies that began before 2020.)\nThe charts also sow a clear dip in trade at the start of the pandemic in early 2020, followed by a gradual recovery, before dipping again in early 2022 when Russia began its military actions in the Ukraine."
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex04/Take-home_Ex04.html#animated-bar-charts",
    "href": "Take-home_Ex/Take-Home_Ex04/Take-home_Ex04.html#animated-bar-charts",
    "title": "Trade Trends",
    "section": "Animated bar charts",
    "text": "Animated bar charts\nWe may also be interested to see how the composition and relative ranking of Singapore’s top 10 trading partners (in terms of imports and exports) have changed over the three-year period. To visualise this, I have developed animated bar chartsusing the gganimate package, which show the top 10 economies in descending order of trading volumes, at the end of each month during the period of study. The animations are shown in .gif form after the codes.\n\n\n\nImportsExports\n\n\n\nImports_td <- trade_data %>%\n  filter(Economy==\"Mainland China\" | Economy==\"Malaysia\" | \n           Economy==\"United States\"| Economy==\"Taiwan\" | Economy==\"Hong Kong\" |\n           Economy==\"Indonesia\" | Economy==\"Republic Of Korea\" |\n           Economy==\"Japan\" | Economy==\"Thailand\" | Economy==\"Australia\" |\n           Economy==\"Vietnam, Socialist Republic Of\" | \n           Economy==\"United Arab Emirates\" | Economy==\"Philippines\" |\n           Economy==\"Germany, Federal Republic Of\" | Economy==\"France\" |\n           Economy==\"Switzerland\" | Economy==\"Netherlands\" |\n           Economy==\"United Kingdom\" | Economy==\"Saudi Arabia\" |\n           Economy==\"Brazil\") %>%\n  mutate(Economy = if_else(Economy==\"Mainland China\", \"China\", Economy)) %>%\n  mutate(Economy = if_else(Economy==\"Vietnam, Socialist Republic Of\", \"Vietnam\",\n                           Economy)) %>%\n  mutate(Economy = if_else(Economy==\"Germany, Federal Republic Of\", \"Germany\",\n                           Economy))  %>%\n  mutate(Economy = if_else(Economy==\"Republic Of Korea\", \"South Korea\",\n                           Economy))  %>%\n  mutate(Economy = if_else(Economy==\"United Arab Emirates\", \"U.A.E.\",\n                           Economy))  %>%\n  select(Economy, Date, Imports) %>%\n  group_by(Date) %>%\n  mutate(rank = rank(-Imports),\n         Imports_rel = Imports/Imports[rank==1],\n         Imports_lbl = paste0(\" \",round(Imports/1000))) %>%\n  group_by(Economy) %>% \n  filter(rank <=10) %>%\n  ungroup()\n\np25 <- ggplot(Imports_td, aes(rank, group=Economy, fill=as.factor(Economy),\n                              color=as.factor(Economy))) +\n  geom_tile(aes(y=Imports/2, height=Imports, width=0.9), alpha=0.8, color=NA) +\n  geom_text(aes(y=0, label=paste(Economy, \" \")), vjust=0.2, hjust=1, size=14) +\n  geom_text(aes(y=Imports, label=Imports_lbl), hjust=0, size=14) +\n  coord_flip(clip=\"off\", expand=FALSE) +\n  scale_y_continuous(labels=scales::label_comma()) +\n  scale_x_reverse() +\n  guides(color=none, fill=none) +\n  theme(axis.line=element_blank(),\n        axis.text.x=element_blank(),\n        axis.text.y=element_blank(),\n        axis.ticks=element_blank(),\n        axis.title.x=element_blank(),\n        axis.title.y=element_blank(),\n        legend.position=\"none\",\n        panel.background=element_blank(),\n        panel.border=element_blank(),\n        panel.grid.major=element_blank(),\n        panel.grid.minor=element_blank(),\n        panel.grid.major.x = element_line(linewidth=.1, color=\"grey\" ),\n        panel.grid.minor.x = element_line(linewidth=.1, color=\"grey\" ),\n        plot.title=element_text(size=50),\n        plot.subtitle=element_text(size=30),\n        plot.caption =element_text(size=30),\n        plot.background=element_blank(),\n        plot.margin = margin(4, 4, 4, 12, \"cm\")) +\n  transition_states(Date, transition_length = 4, state_length = 1, wrap = FALSE) +\n  view_follow(fixed_x = TRUE)  +\n  labs(title = \"Import Volumes: {previous_state}\",\n       subtitle  =  \"\\nTop 10 Economies\\n\",\n       caption  = \"\\nVolumes in millions SGD\")\n\n# The code below will not be run automatically, but the output gif is shown\n# below this section.\n\n#animate(p25, 300, fps = 10,  width = 1600, height = 1400, \n#        renderer = gifski_renderer(\"gganim1.gif\"))\n\n\n\n\nExports_td <- trade_data %>%\n  filter(Economy==\"Mainland China\" | Economy==\"Malaysia\" | \n           Economy==\"United States\"| Economy==\"Taiwan\" | Economy==\"Hong Kong\" |\n           Economy==\"Indonesia\" | Economy==\"Republic Of Korea\" |\n           Economy==\"Japan\" | Economy==\"Thailand\" | Economy==\"Australia\" |\n           Economy==\"Vietnam, Socialist Republic Of\" | \n           Economy==\"United Arab Emirates\" | Economy==\"Philippines\" |\n           Economy==\"Germany, Federal Republic Of\" | Economy==\"France\" |\n           Economy==\"Switzerland\" | Economy==\"Netherlands\" |\n           Economy==\"United Kingdom\" | Economy==\"Saudi Arabia\" |\n           Economy==\"Brazil\") %>%\n  mutate(Economy = if_else(Economy==\"Mainland China\", \"China\", Economy)) %>%\n  mutate(Economy = if_else(Economy==\"Vietnam, Socialist Republic Of\", \"Vietnam\",\n                           Economy)) %>%\n  mutate(Economy = if_else(Economy==\"Germany, Federal Republic Of\", \"Germany\",\n                           Economy))  %>%\n  mutate(Economy = if_else(Economy==\"Republic Of Korea\", \"South Korea\",\n                           Economy))  %>%\n  mutate(Economy = if_else(Economy==\"United Arab Emirates\", \"U.A.E.\",\n                           Economy))  %>%\n  select(Economy, Date, Exports) %>%\n  group_by(Date) %>%\n  mutate(rank = rank(-Exports),\n         Exports_rel = Exports/Exports[rank==1],\n         Exports_lbl = paste0(\" \",round(Exports/1000))) %>%\n  group_by(Economy) %>% \n  filter(rank <=10) %>%\n  ungroup()\n\np26 <- ggplot(Exports_td, aes(rank, group=Economy, fill=as.factor(Economy),\n                              color=as.factor(Economy))) +\n  geom_tile(aes(y=Exports/2, height=Exports, width=0.9), alpha=0.8, color=NA) +\n  geom_text(aes(y=0, label=paste(Economy, \" \")), vjust=0.2, hjust=1, size=14) +\n  geom_text(aes(y=Exports, label=Exports_lbl), hjust=0, size=14) +\n  coord_flip(clip=\"off\", expand=FALSE) +\n  scale_y_continuous(labels=scales::label_comma()) +\n  scale_x_reverse() +\n  guides(color=none, fill=none) +\n  theme(axis.line=element_blank(),\n        axis.text.x=element_blank(),\n        axis.text.y=element_blank(),\n        axis.ticks=element_blank(),\n        axis.title.x=element_blank(),\n        axis.title.y=element_blank(),\n        legend.position=\"none\",\n        panel.background=element_blank(),\n        panel.border=element_blank(),\n        panel.grid.major=element_blank(),\n        panel.grid.minor=element_blank(),\n        panel.grid.major.x = element_line(linewidth=.1, color=\"grey\" ),\n        panel.grid.minor.x = element_line(linewidth=.1, color=\"grey\" ),\n        plot.title=element_text(size=50),\n        plot.subtitle=element_text(size=30),\n        plot.caption =element_text(size=30),\n        plot.background=element_blank(),\n        plot.margin = margin(4, 4, 4, 12, \"cm\")) +\n  transition_states(Date, transition_length = 4, state_length = 1, wrap = FALSE) +\n  view_follow(fixed_x = TRUE)  +\n  labs(title = \"Export Volumes: {previous_state}\",\n       subtitle  =  \"\\nTop 10 Economies\\n\",\n       caption  = \"\\nVolumes in millions SGD\")\n\n# The code below will not be run automatically, but the output gif is shown\n# below this section.\n\n#animate(p26, 300, fps = 10,  width = 1600, height = 1400, \n#        renderer = gifski_renderer(\"gganim2.gif\"))\n\n\n\n\n\n\n\n\nPatterns observed:\nChina and Malaysia dominated the top 2 positions in terms of import volumes. However, the largest import volumes in mid-2021 and early 2022 were from Taiwan. There does not appear to be any seasonality in these occurrences. Perhaps they were the result sudden and large microchip imports from Taiwan (the world’s main microchip producer), boosted by increased prices due to the shortage. Japan and South Korea remained consistently in the middle of the top 10. Indonesia was always in the top 10 but bottom 4, while various economies including Australia, France, Germany, Saudi Arabia, Switzerland, Thailand and the United Arab Emirates would move in and out of the group.\nInterestingly, despite trade in Singapore being primarily transit and transshipment, the composition of top 10 trading partners in terms of export volumes was more consistent than that for import volumes. Hong Kong, which is not a top 10 trading partner in terms of import volumes, is consistently in the top 2 positions. Major oil exporters Saudi Arabia and the United Arab Emirates do not appear in the top 10 for imports at all, and the only European country to show is the Netherlands."
  }
]