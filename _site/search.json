[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This site was created as a requirement of the Singapore Management University’s ISSS608 Visual Analytics and Applications course (January 2023 term). The site creator is a student in the university’s Master of Information Technology in Business (MITB).\nThank you for visiting.\n\nfarrahmf"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The code below uses the pacman package’s p_load() to check if tidyverse is installed. If it is, it will be launched into R.\n\npacman::p_load(tidyverse)\n\n\n\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x = RACE)) +\n  geom_bar()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "href": "Hands-on_Ex/Hands-on_Ex03/Hands-on_Ex03.html",
    "title": "Hands-on Exercise 3",
    "section": "",
    "text": "1. Installing packages\n\npacman::p_load(ggiraph, plotly, gganimate, DT, patchwork, tidyverse)\n\n\n\n2. Importing data\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n3. Tooltip\nUsing aesthetic tooltip = ID and girafe() to display the id of an element when the mouse hovers over it.\n\np <- ggplot(data = exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\"\n  ) +\n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(ggobj = p,\n       width_svg = 6,\n       height_svg = 6*0.618)\n\n\n\n\n\nDisplaying customised information by creating a new object.\ngirafe(ggobj = p,\nwidth_svg = 8,\nheight_svg = 8*0.618\n)\n\nexam_data$tooltip <- c(paste0(\n  \"Name = \", exam_data$ID,\n  \"\\n Class = \", exam_data$CLASS\n))\n\np <- ggplot(data = exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\"\n  ) +\n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(ggobj = p,\n       width_svg = 8,\n       height_svg = 8*0.618\n)\n\n\n\n\n\nCustomise tooltop style using opts_tooltip() and css declarations.\n\ntooltip_css <- \"background-color:DarkSlateGrey; font-family: Arial, Times, serif; color:LightYellow;\"\n\np <- ggplot(data = exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = exam_data$tooltip),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\"\n  ) +\n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(ggobj = p,\n       width_svg = 8,\n       height_svg = 8*0.618,\n       options = list(\n         opts_tooltip(\n           css = tooltip_css\n         )\n       )\n)\n\n\n\n\n\nDisplaying statistics on tooltip.\n\ntooltip <- function(y, ymax, accuracy = .01) {\n  mean <- scales::number(y, accuracy = accuracy)\n  sem <- scales::number(ymax - y, accuracy = accuracy)\n  paste(\"Mean maths scores:\", mean, \"+/-\", sem)\n}\n\ngg_point <- ggplot(data = exam_data,\n                   aes(x = RACE)) +\n  stat_summary(aes(y = MATHS,\n                   tooltip = after_stat(\n                     tooltip(y, ymax))), \n               fun.data = \"mean_se\",\n               geom = GeomInteractiveCol,\n               fill = \"#66CC99\") +\n  stat_summary(aes(y = MATHS),\n               fun.data = mean_se,\n               geom = \"errorbar\", width = 0.2, linewidth = 0.2)\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\nWarning: Using the `size` aesthetic in this geom was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` in the `default_aes` field and elsewhere instead.\n\n\n\n\n\n\nHighlighting elements associated with a data_id.\n\np <- ggplot(data = exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(data_id = CLASS),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\"\n  ) +\n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(ggobj = p,\n       width_svg = 8,\n       height_svg = 8*0.618\n)\n\n\n\n\n\nAs above, but inverting the highlight (i.e. lowlighting elements not associated with the data_id instead).\n\np <- ggplot(data = exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(data_id = CLASS),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\"\n  ) +\n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(ggobj = p,\n       width_svg = 8,\n       height_svg = 8*0.618,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2;\")\n       )\n)\n\n\n\n\n\nUsing onclick to link to a website.\n\nexam_data$onclick <- sprintf(\"window.open(\\\"%s%s\\\")\",\n                             \"https://www.moe.gov.sg/schoolfinder?journey=Primary%20school\", \n                             as.character(exam_data$ID))\n\np <- ggplot(data = exam_data,\n            aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(onclick = onclick),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\"\n  ) +\n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(ggobj = p,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\nCoordinated multiple views, using ggiraph and patchwork: when a data point on one plot is selected, the corresponding data point (i.e. sharing the same data ID) in another plot will be highlighted too.\n\np1 <- ggplot(data = exam_data,\n             aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(data_id = ID),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\"\n  ) +\n  coord_cartesian(xlim = c(0,100)) +\n  scale_y_continuous(NULL, breaks = NULL)\n\np2 <- ggplot(data = exam_data,\n             aes(x = ENGLISH)) +\n  geom_dotplot_interactive(\n    aes(data_id = ID),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\"\n  ) +\n  coord_cartesian(xlim = c(0,100)) +\n  scale_y_continuous(NULL, breaks = NULL)\n\ngirafe(code = print(p1/p2),\n       width_svg = 6,\n       height_svg = 6,\n       options = list(\n         opts_hover(css = \"fill: #202020;\"),\n         opts_hover_inv(css = \"opacity:0.2\")\n       )\n       )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html",
    "title": "Hands-on Exercise 4(1)",
    "section": "",
    "text": "pacman::p_load(ggstatsplot, rstantools, PMCMRplus, tidyverse)\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nUsing gghistostats().\n\nset.seed(1234)\n\ngghistostats(\n  data = exam_data,\n  x = ENGLISH,\n  type = \"bayes\",\n  test.value = 60,\n  xlab = \"English scores\"\n)\n\n\n\n\n\n\n\nUsing ggbetweenstats().\n\nggbetweenstats(\n  data = exam_data,\n  x = GENDER,\n  y = MATHS,\n  type = \"np\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\nUsing ggbetweenstats().\n\nggbetweenstats(\n  data = exam_data,\n  x = RACE,\n  y = ENGLISH,\n  type = \"p\",\n  mean.ci = TRUE,\n  pairwise.comparisons = TRUE,\n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\n\n\n\n\n\n\nUsing ggscatterscats().\n\nggscatterstats(\n  data = exam_data,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE\n)\n\n\n\n\n\n\n\nUsing ggbarstats().\n\nexam1 <- exam_data %>%\n  mutate(MATHS_bins =\n           cut(MATHS,\n               breaks = c(0, 60, 75, 85, 100)))\n\nggbarstats(exam1,\n           x = MATHS_bins,\n           y = GENDER)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#visualising-models",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_1.html#visualising-models",
    "title": "Hands-on Exercise 4(1)",
    "section": "Visualising Models",
    "text": "Visualising Models\n\nLoading packages and installing data\n\npacman::p_load(readxl, performance, parameters, see)\n\ncar_resale <- read_xls(\"data/ToyotaCorolla.xls\", \"data\")\n\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model       Price Age_0…¹ Mfg_M…² Mfg_Y…³     KM Quart…⁴ Weight Guara…⁵\n   <dbl> <chr>       <dbl>   <dbl>   <dbl>   <dbl>  <dbl>   <dbl>  <dbl>   <dbl>\n 1    81 TOYOTA Cor… 18950      25       8    2002  20019     100   1180       3\n 2     1 TOYOTA Cor… 13500      23      10    2002  46986     210   1165       3\n 3     2 TOYOTA Cor… 13750      23      10    2002  72937     210   1165       3\n 4     3  TOYOTA Co… 13950      24       9    2002  41711     210   1165       3\n 5     4 TOYOTA Cor… 14950      26       7    2002  48000     210   1165       3\n 6     5 TOYOTA Cor… 13750      30       3    2002  38500     210   1170       3\n 7     6 TOYOTA Cor… 12950      32       1    2002  61000     210   1170       3\n 8     7  TOYOTA Co… 16900      27       6    2002  94612     210   1245       3\n 9     8 TOYOTA Cor… 18600      30       3    2002  75889     210   1245       3\n10    44 TOYOTA Cor… 16950      27       6    2002 110404     234   1255       3\n# … with 1,426 more rows, 28 more variables: HP_Bin <chr>, CC_bin <chr>,\n#   Doors <dbl>, Gears <dbl>, Cylinders <dbl>, Fuel_Type <chr>, Color <chr>,\n#   Met_Color <dbl>, Automatic <dbl>, Mfr_Guarantee <dbl>,\n#   BOVAG_Guarantee <dbl>, ABS <dbl>, Airbag_1 <dbl>, Airbag_2 <dbl>,\n#   Airco <dbl>, Automatic_airco <dbl>, Boardcomputer <dbl>, CD_Player <dbl>,\n#   Central_Lock <dbl>, Powered_Windows <dbl>, Power_Steering <dbl>,\n#   Radio <dbl>, Mistlamps <dbl>, Sport_Model <dbl>, Backseat_Divider <dbl>, …\n\n\n\n\nMultiple Regression Model\nUsing lm() from Base Stats of R.\n\nmodel <- lm(Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period,\n            data = car_resale)\n\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\n\nModel Diagnostic: Checking for multicollinearity\nUsing check_collinearity() from the performance package.\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Guarantee_Period  1.04   [1.01, 1.17]         1.02      0.97     [0.86, 0.99]\n        Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n         Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\nHigh Correlation\n\n   Term  VIF   VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n     KM 1.46 [1.37, 1.57]         1.21      0.68     [0.64, 0.73]\n Weight 1.41 [1.32, 1.51]         1.19      0.71     [0.66, 0.76]\n\n\n\ncheck_c <- check_collinearity(model)\nplot(check_c)\n\nVariable `Component` is not in your data frame :/\n\n\n\n\n\n\n\nModel Diagnostic: Checking normality assumption\nUsing check_normality() from the performance package.\n\nmodel1 <- lm(Price ~ Age_08_04 + KM + Weight + Guarantee_Period,\n             data = car_resale)\n\ncheck_n <- check_normality(model1)\n\nplot(check_n)\n\n\n\n\n\n\nModel Diagnostic: Checking for heteroscedasticity\nUsing check_heteroscedasticity() from the performance package.\n\ncheck_h <- check_heteroscedasticity(model1)\n\nplot(check_h)\n\n\n\n\n\n\nModel Diagnostic: Complete check\nUsing check_model().\n\ncheck_model(model1)\n\nVariable `Component` is not in your data frame :/\n\n\n\n\n\n\n\nVisualising Regression Parameters\nUsing plot() of see package and parameters() of parameters package to visualise the parameters of a regression model.\n\nplot(parameters(model1))\n\n\n\n\nUsing ggcoefstats() of ggstatsplot package to visualise the parameters of a regression model.\n\nggcoefstats(model1, output = \"plot\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_2.html",
    "title": "Hands-on Exercise 4(2)",
    "section": "",
    "text": "pacman::p_load(plotly, crosstalk, DT, ggiraph, ggdist, gganimate, tidyverse)\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\nUsing ggplot2. First, group observations and tabulate count, mean, standard deviation and standard error for each group.\n\nmy_sum <- exam_data %>%\n  group_by(RACE) %>%\n  summarise(\n    n = n(),\n    mean = mean(MATHS),\n    sd = sd(MATHS)\n  ) %>%\n  mutate(se = sd/sqrt(n-1))\n\nmy_sum\n\n# A tibble: 4 × 5\n  RACE        n  mean    sd    se\n  <chr>   <int> <dbl> <dbl> <dbl>\n1 Chinese   193  76.5  15.7  1.13\n2 Indian     12  60.7  23.4  7.04\n3 Malay     108  57.4  21.1  2.04\n4 Others      9  69.7  10.7  3.79\n\n\nVisualise as a table, using kable().\n\nknitr::kable(head(my_sum), format = 'html')\n\n\n\n \n  \n    RACE \n    n \n    mean \n    sd \n    se \n  \n \n\n  \n    Chinese \n    193 \n    76.50777 \n    15.69040 \n    1.132357 \n  \n  \n    Indian \n    12 \n    60.66667 \n    23.35237 \n    7.041005 \n  \n  \n    Malay \n    108 \n    57.44444 \n    21.13478 \n    2.043177 \n  \n  \n    Others \n    9 \n    69.66667 \n    10.72381 \n    3.791438 \n  \n\n\n\n\n\nVisualising on a chart.\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(aes\n           (x=RACE, \n            y=mean), \n           stat=\"identity\", \n           color=\"red\",\n           size = 1.5,\n           alpha=1) +\n  ggtitle(\"Standard error of mean \n          maths score by race\")\n\nWarning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\nℹ Please use `linewidth` instead.\n\n\n\n\n\n\n# for 95% confidence interval, ordered by mean\n\ntcrit <- qnorm(0.025)\n\nmy_sum$tooltip <- c(paste0(\n  \"Race = \", my_sum$RACE,\n  \"\\n N = \", my_sum$n,\n  \"\\n Avg. Scores = \", my_sum$mean,\n  \"\\n 95% CI: [\", my_sum$mean-(tcrit*my_sum$se), \" , \", my_sum$mean+(tcrit*my_sum$se), \"]\"\n))\n\np <- ggplot(my_sum) +\n  geom_errorbar(\n    aes(x = reorder(RACE, -mean), ymin = mean-(tcrit*se), ymax = mean+(tcrit*se)),\n    width = 0.2, colour = \"black\", alpha = 0.9, size = 0.5) +\n  geom_point_interactive(\n    aes(x = reorder(RACE, -mean), y = mean, tooltip = my_sum$tooltip), \n    stat = \"identity\", colour = \"red\", size = 1.5, alpha = 1) +\n  ggtitle(\"Standard error of mean maths score by race\")\n\ngirafe(ggobj = p,\n       width_svg = 8,\n       height_svg = 8*0.618\n)\n\nWarning: Use of `my_sum$tooltip` is discouraged.\nℹ Use `tooltip` instead.\n\n\n\n\n\n\n\n\n\nUsing stat_pointinterval() to build a visual for displaying distribution of maths scores by race.\n\nexam_data %>%\n  ggplot(aes(x = RACE,\n             y = MATHS)) +\n  stat_pointinterval() +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\"\n  )\n\n\n\n\nNote: for the below, from prof’s slides, .point and .interval are ignored, replaced by point_interval per documentation however using point_interval = “median.qi” does not work. Resulting chart looks the same though.\n\nexam_data %>%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = 0.95) +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\nMakeover the plot on previous slide by showing 95% and 99% confidence intervals.\n\nexam_data %>%\n  ggplot(aes(x = RACE, y = MATHS)) +\n  stat_pointinterval(.width = c(0.95,0.99)) +\n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Mean Point + Multiple-interval plot\")\n\n\n\n\nUsing stat_gradientinterval() from ggdist package to build a visual displaying distribution of maths scores by race.\n\nexam_data %>%\n  ggplot(aes(x = RACE, \n             y = MATHS)) +\n  stat_gradientinterval(   \n    fill = \"skyblue\",      \n    show.legend = TRUE     \n  ) +                        \n  labs(\n    title = \"Visualising confidence intervals of mean math score\",\n    subtitle = \"Gradient + interval plot\")\n\nWarning: fill_type = \"gradient\" is not supported by the current graphics device.\n - Falling back to fill_type = \"segments\".\n - If you believe your current graphics device *does* support\n   fill_type = \"gradient\" but auto-detection failed, set that option\n   explicitly and consider reporting a bug.\n - See help(\"geom_slabinterval\") for more information.\n\n\n\n\n\n\n\n\n(Hypothetical Outcome Plots)\nNot able to run the code and including it prevents successful rendering of website."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html",
    "title": "Hands-on Exercise 4(3)",
    "section": "",
    "text": "pacman::p_load(tidyverse, FunnelPlotR, plotly, knitr)\n\ncovid19 <- read_csv(\"data/COVID-19_DKI_Jakarta.csv\") %>%\n  mutate_if(is.character, as.factor)\n\nRows: 267 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): City, District, Sub-district\ndbl (4): Sub-district ID, Positive, Recovered, Death\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\ncovid19\n\n# A tibble: 267 × 7\n   `Sub-district ID` City            District      Sub-d…¹ Posit…² Recov…³ Death\n               <dbl> <fct>           <fct>         <fct>     <dbl>   <dbl> <dbl>\n 1        3172051003 JAKARTA UTARA   PADEMANGAN    ANCOL      1776    1691    26\n 2        3173041007 JAKARTA BARAT   TAMBORA       ANGKE      1783    1720    29\n 3        3175041005 JAKARTA TIMUR   KRAMAT JATI   BALE K…    2049    1964    31\n 4        3175031003 JAKARTA TIMUR   JATINEGARA    BALI M…     827     797    13\n 5        3175101006 JAKARTA TIMUR   CIPAYUNG      BAMBU …    2866    2792    27\n 6        3174031002 JAKARTA SELATAN MAMPANG PRAP… BANGKA     1828    1757    26\n 7        3175051002 JAKARTA TIMUR   PASAR REBO    BARU       2541    2433    37\n 8        3175041004 JAKARTA TIMUR   KRAMAT JATI   BATU A…    3608    3445    68\n 9        3171071002 JAKARTA PUSAT   TANAH ABANG   BENDUN…    2012    1937    38\n10        3175031002 JAKARTA TIMUR   JATINEGARA    BIDARA…    2900    2773    52\n# … with 257 more rows, and abbreviated variable names ¹​`Sub-district`,\n#   ²​Positive, ³​Recovered\n\n\nBasic funnel plot.\n\nfunnel_plot(\n  numerator = covid19$Positive,\n  denominator = covid19$Death,\n  group = covid19$`Sub-district`\n)\n\n\n\n\nA funnel plot object with 267 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\nMade over by changing data type to proportions and recalibrating the x and y axes…\n\nfunnel_plot(\n  numerator = covid19$Death,\n  denominator = covid19$Positive,\n  group = covid19$`Sub-district`,\n  data_type = \"PR\",   \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #<<           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #<<\n  y_label = \"Cumulative Fatality Rate\"  #<<\n)\n\nWarning: The `xrange` argument deprecated; please use the `x_range` argument\ninstead. For more options, see the help: `?funnel_plot`\n\n\nWarning: The `yrange` argument deprecated; please use the `y_range` argument\ninstead. For more options, see the help: `?funnel_plot`\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion. \n\n\n… with more appropriate labelling\n\nfunnel_plot(\n  numerator = covid19$Death,\n  denominator = covid19$Positive,\n  group = covid19$`Sub-district`,\n  data_type = \"PR\",   \n  xrange = c(0, 6500),  \n  yrange = c(0, 0.05),\n  label = NA,\n  title = \"Cumulative COVID-19 Fatality Rate by Cumulative Total Number of COVID-19 Positive Cases\", #<<           \n  x_label = \"Cumulative COVID-19 Positive Cases\", #<<\n  y_label = \"Cumulative Fatality Rate\"  #<<\n)\n\nWarning: The `xrange` argument deprecated; please use the `x_range` argument\ninstead. For more options, see the help: `?funnel_plot`\n\n\nWarning: The `yrange` argument deprecated; please use the `y_range` argument\ninstead. For more options, see the help: `?funnel_plot`\n\n\n\n\n\nA funnel plot object with 267 points of which 7 are outliers. \nPlot is adjusted for overdispersion."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#funnel-plots-using-ggplot2",
    "href": "Hands-on_Ex/Hands-on_Ex04/Hands-on_Ex04_3.html#funnel-plots-using-ggplot2",
    "title": "Hands-on Exercise 4(3)",
    "section": "Funnel plots using ggplot2",
    "text": "Funnel plots using ggplot2\nFirst, derive cumulative death rate and its standard error.\n\ndf <- covid19 %>%\n  mutate(rate = Death / Positive) %>%\n  mutate(rate.se = sqrt((rate*(1-rate)) / (Positive))) %>%\n  filter(rate > 0)\n\nCompute fit.mean (what is?)\n\nfit.mean <- weighted.mean(df$rate, 1/df$rate.se^2)\n\nCalculate the 95% and 99% confidence intervals\n\nnumber.seq <- seq(1, max(df$Positive), 1)\nnumber.ll95 <- fit.mean - 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul95 <- fit.mean + 1.96 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ll999 <- fit.mean - 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \nnumber.ul999 <- fit.mean + 3.29 * sqrt((fit.mean*(1-fit.mean)) / (number.seq)) \ndfCI <- data.frame(number.ll95, number.ul95, number.ll999, number.ul999, number.seq, fit.mean)\n\nPlotting a static funnel plot (note that “label” is not recognised below, but is needed later for the interactive)\n\np <- ggplot(df, aes(x = Positive, y = rate)) +\n  geom_point(aes(label=`Sub-district`), \n             alpha=0.4) +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll95), \n            linewidth = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul95), \n            linewidth = 0.4, \n            colour = \"grey40\", \n            linetype = \"dashed\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ll999), \n            linewidth = 0.4, \n            colour = \"grey40\") +\n  geom_line(data = dfCI, \n            aes(x = number.seq, \n                y = number.ul999), \n            linewidth = 0.4, \n            colour = \"grey40\") +\n  geom_hline(data = dfCI, \n             aes(yintercept = fit.mean), \n             linewidth = 0.4, \n             colour = \"grey40\") +\n  coord_cartesian(ylim=c(0,0.05)) +\n  annotate(\"text\", x = 1, y = -0.13, label = \"95%\", size = 3, colour = \"grey40\") + \n  annotate(\"text\", x = 4.5, y = -0.18, label = \"99%\", size = 3, colour = \"grey40\") + \n  ggtitle(\"Cumulative Fatality Rate by Cumulative Number of COVID-19 Cases\") +\n  xlab(\"Cumulative Number of COVID-19 Cases\") + \n  ylab(\"Cumulative Fatality Rate\") +\n  theme_light() +\n  theme(plot.title = element_text(size=12),\n        legend.position = c(0.91,0.85), \n        legend.title = element_text(size=7),\n        legend.text = element_text(size=7),\n        legend.background = element_rect(colour = \"grey60\", linetype = \"dotted\"),\n        legend.key.height = unit(0.3, \"cm\"))\n\nWarning in geom_point(aes(label = `Sub-district`), alpha = 0.4): Ignoring\nunknown aesthetics: label\n\np\n\n\n\n\nMaking it interactive.\n\nfp_ggplotly <- ggplotly(p,\n  tooltip = c(\"label\", \n              \"x\", \n              \"y\"))\nfp_ggplotly"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05.html",
    "title": "Hands-on Exercise 5(1)",
    "section": "",
    "text": "pacman::p_load(ggtern, plotly, tidyverse)\npop_data <- read_csv(\"data/respopagsex2000to2018_tidy.csv\")\n\nDerive three new variables - ‘YOUNG’, ‘ACTIVE’ and ‘OLD’ - from the existing age group variables.\n\nagpop_mutated <- pop_data %>%\n  mutate('Year' = as.character(Year)) %>%\n  spread(AG, Population) %>%\n  mutate(YOUNG = rowSums(.[4:8])) %>%\n  mutate(ACTIVE = rowSums(.[9:16])) %>%\n  mutate(OLD = rowSums(.[17:21])) %>%\n  mutate(TOTAL = rowSums(.[22:24])) %>%\n  filter(Year == 2018) %>%\n  filter(TOTAL > 0)\n\n\n\n\nStatic:\n\nggtern(data = agpop_mutated, aes(x = YOUNG, y = ACTIVE, z = OLD)) +\n  geom_point() +\n  labs(title = \"Population structure, 2015\") +\n  theme_rgbw()\n\n\n\n\nInteractive:\n\nlabel <- function(txt) {\n  list(\n    text = txt,\n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\",\n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\naxis <- function(txt) {\n  list(title = txt, tickformat = \".0%\", tickfont = list(size = 10))\n}\n\nternaryAxes <- list(\n  aaxis = axis(\"Young\"),\n  baxis = axis(\"Active\"),\n  caxis = axis(\"Old\")\n)\n\nplot_ly(\n  agpop_mutated,\n  a = ~YOUNG,\n  b = ~ACTIVE,\n  c = ~OLD,\n  color = I(\"black\"),\n  type = \"scatterternary\"\n) %>%\n  layout(\n    annotations = label(\"Ternary Markers\"),\n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_2.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_2.html",
    "title": "Hands-on Exercise 5(2)",
    "section": "",
    "text": "Correlation Matrices\n\nLoading packages and importing data\n\npacman::p_load(corrplot, ggstatsplot, tidyverse)\nwine <- read_csv(\"data/wine_quality.csv\")\n\n\n\nUsing pairs()\n\npairs(wine[,1:11])\n\n\n\n\n\npairs(wine[,2:12], lower.panel = NULL)\n\n\n\n\nShowing the correlation coefficient of each pair of variables:\n\npanel.cor <- function(x, y, digits = 2, prefix = \"\", cex.cor, ...) {\n  usr <- par(\"usr\")\n  on.exit(par(usr))\n  par(usr = c(0, 1, 0, 1))\n  r <- abs(cor(x, y, use = \"complete.obs\"))\n  txt <- format(c(r, 0.123456789), digits = digits)[1]\n  txt <- paste(prefix, txt, sep = \"\")\n  if(missing(cex.cor)) cex.cor <- 0.8/strwidth(txt)\n  text(0.5, 0.5, txt, cex = cex.cor * (1 + r)/2)\n}\n\npairs(wine[,2:12], upper.panel = panel.cor)\n\n\n\n\n\n\nUsing ggcorrmat()\nCode below won’t run, error message:\nError in titleGrob(label, x, y, hjust = hj, vjust = vj, angle = angle, :\nunused argument (expand_y = TRUE)\n\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)\n\n\n\n\n\n\nUsing corrplot()\n\nwine.cor <- cor(wine[, 1:11])\ncorrplot(wine.cor, method = \"shade\", type = \"lower\", diag = FALSE, tl.col = \"black\")\n\n\n\n\nCombining with significance test:\n\nwine.sig = cor.mtest(wine.cor, conf.level = 0.95)\n\n\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05)\n\n\n\n\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")\n\n\n\n\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order=\"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3)"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_3.html",
    "href": "Hands-on_Ex/Hands-on_Ex05/Hands-on_Ex05_3.html",
    "title": "Hands-on Exercise 5(3)",
    "section": "",
    "text": "pacman::p_load(seriation, dendextend, heatmaply, tidyverse)\nwh <- read_csv(\"data/WHData-2018.csv\")\n\n\n\n\nReplace the row names (currently just numbers) with their corresponding country names:\n\nrow.names(wh) <- wh$Country\n\nTransforming to a data matrix:\n\nwh1 <- dplyr::select(wh, c(3, 7:12))  ## what is this for?\nwh_matrix <- data.matrix(wh)\nwh_matrix1 <- data.matrix(wh1) ## added\n\nStatic heatmap with column value indicated by colour intensity:\n\nwh_heatmap <- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "Installing and loading R packages\nTwo packages will be installed and loaded. They are: tidyverse and ggiraph.\n\npacman::p_load(ggiraph, tidyverse)\n\n\n\nImporting data\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nStatic plot:\n\nggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot(dotsize = 0.5)\n\n\n\n\nInteractive plot using ggiraph:\n\np <- ggplot(data=exam_data, \n       aes(x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE, \n    binwidth = 1, \n    method = \"histodot\") +\n  scale_y_continuous(NULL, \n                     breaks = NULL)\ngirafe(\n  ggobj = p,\n  width_svg = 6,\n  height_svg = 6*0.618\n)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "pacman::p_load(plotly, DT, patchwork, ggstatsplot, ggside, tidyverse)\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\n\nplot_ly(data = exam_data,\n        x = ~ENGLISH,\n        y = ~MATHS,\n        color = ~RACE)\n\n\n\n\n\n\np <- ggplot(data=exam_data, \n            aes(x = MATHS,\n                y = ENGLISH)) +\n  geom_point(dotsize = 1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p) #<<\n\n\n\n\n\n\nggbetweenstats(\n  data = exam_data,\n  x = GENDER, \n  y = MATHS,\n  type = \"np\", # non-parametric\n  messages = FALSE\n)\n\n\n\n\n\nggscatterstats(\n  data = exam_data,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = FALSE,\n  )\n\n\n\n\n\nggscatterstats(\n  data = exam_data,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = TRUE,\n  )\n\n\n\n\n\npacman::p_load(readxl, performance, parameters, see, gtsummary)\n\n\ncar_resale <- read_xls(\"data/ToyotaCorolla.xls\", \n                       \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model       Price Age_0…¹ Mfg_M…² Mfg_Y…³     KM Quart…⁴ Weight Guara…⁵\n   <dbl> <chr>       <dbl>   <dbl>   <dbl>   <dbl>  <dbl>   <dbl>  <dbl>   <dbl>\n 1    81 TOYOTA Cor… 18950      25       8    2002  20019     100   1180       3\n 2     1 TOYOTA Cor… 13500      23      10    2002  46986     210   1165       3\n 3     2 TOYOTA Cor… 13750      23      10    2002  72937     210   1165       3\n 4     3  TOYOTA Co… 13950      24       9    2002  41711     210   1165       3\n 5     4 TOYOTA Cor… 14950      26       7    2002  48000     210   1165       3\n 6     5 TOYOTA Cor… 13750      30       3    2002  38500     210   1170       3\n 7     6 TOYOTA Cor… 12950      32       1    2002  61000     210   1170       3\n 8     7  TOYOTA Co… 16900      27       6    2002  94612     210   1245       3\n 9     8 TOYOTA Cor… 18600      30       3    2002  75889     210   1245       3\n10    44 TOYOTA Cor… 16950      27       6    2002 110404     234   1255       3\n# … with 1,426 more rows, 28 more variables: HP_Bin <chr>, CC_bin <chr>,\n#   Doors <dbl>, Gears <dbl>, Cylinders <dbl>, Fuel_Type <chr>, Color <chr>,\n#   Met_Color <dbl>, Automatic <dbl>, Mfr_Guarantee <dbl>,\n#   BOVAG_Guarantee <dbl>, ABS <dbl>, Airbag_1 <dbl>, Airbag_2 <dbl>,\n#   Airco <dbl>, Automatic_airco <dbl>, Boardcomputer <dbl>, CD_Player <dbl>,\n#   Central_Lock <dbl>, Powered_Windows <dbl>, Power_Steering <dbl>,\n#   Radio <dbl>, Mistlamps <dbl>, Sport_Model <dbl>, Backseat_Divider <dbl>, …\n\n\n\nmodel <- lm(Price ~ Age_08_04 + Mfg_Year + KM + \n              Weight + Guarantee_Period, data = car_resale)\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\n\ntable1 <- tbl_regression(model, intercept = TRUE)\n\ntable1\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n-2,636,783\n-3,150,331, -2,123,236\n<0.001\n    Age_08_04\n-14\n-35, 7.1\n0.2\n    Mfg_Year\n1,315\n1,059, 1,571\n<0.001\n    KM\n-0.02\n-0.03, -0.02\n<0.001\n    Weight\n19\n17, 21\n<0.001\n    Guarantee_Period\n28\n3.8, 52\n0.023\n  \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\n\ncheck_c <- check_collinearity(model)\nplot(check_c)\n\n\n\n\n\nmodel1 <- lm(Price ~ Age_08_04 + KM + \n              Weight + Guarantee_Period, data = car_resale)\n\n\ncheck_n <- check_normality(model1)\n\n\nplot(check_n)\n\n\n\n\n\ncheck_model(model1)\n\n\n\n\n\nplot(parameters(model1))\n\n\n\n\n\nggcoefstats(model1, \n            output = \"plot\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "In-class Exercise 5 - Correlation Matrices",
    "section": "",
    "text": "pacman::p_load(corrplot, tidyverse, ggstatsplot)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#correlation-matrices",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#correlation-matrices",
    "title": "In-class Exercise 5 - Correlation Matrices",
    "section": "Correlation Matrices",
    "text": "Correlation Matrices\n\nggstatsplot::ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  ggcorrplot.args = list(outline.color = \"black\",\n                         hc.order = TRUE,\n                         tl.cex = 15),  ## \"X\" size\n  title = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are not significant at p < 0.05\"\n)\n\n\n\n\n\ngrouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)\n\n\n\n\n\nwine.cor <- cor(wine[, 1:11])\n\n\ncorrplot(wine.cor,\n         method = \"ellipse\",\n         type=\"lower\",\n         diag = FALSE,\n         tl.col = \"black\")\n\n\n\n\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               tl.col = \"black\")\n\n\n\n\n\nwine.sig = cor.mtest(wine.cor, conf.level= .95)\n\n\ncorrplot(wine.cor,\n         method = \"number\",\n         type = \"lower\",\n         diag = FALSE,\n         tl.col = \"black\",\n         tl.srt = 45,\n         p.mat = wine.sig$p,\n         sig.level = .05)\n\n\n\n\n\ncorrplot.mixed(wine.cor, \n               lower = \"ellipse\", \n               upper = \"number\",\n               tl.pos = \"lt\",\n               diag = \"l\",\n               order=\"AOE\",\n               tl.col = \"black\")\n\n\n\n\n\ncorrplot(wine.cor, \n         method = \"ellipse\", \n         tl.pos = \"lt\",\n         tl.col = \"black\",\n         order=\"hclust\",\n         hclust.method = \"ward.D\",\n         addrect = 3)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05_2.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05_2.html",
    "title": "In-class Exercise 5 - Ternary Plots and Heat Maps",
    "section": "",
    "text": "pacman::p_load(ggtern, plotly, seriation, dendextend, heatmaply, tidyverse)\npop_data <- read_csv(\"data/respopagsex2000to2018_tidy.csv\") \nwh <- read_csv(\"data/WHData-2018.csv\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05_2.html#ternary-plots",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05_2.html#ternary-plots",
    "title": "In-class Exercise 5 - Ternary Plots and Heat Maps",
    "section": "Ternary Plots",
    "text": "Ternary Plots\n\nagpop_mutated <- pop_data %>%\n  mutate(`Year` = as.character(Year))%>%\n  spread(AG, Population) %>%\n  mutate(YOUNG = rowSums(.[4:8]))%>%\n  mutate(ACTIVE = rowSums(.[9:16]))  %>%\n  mutate(OLD = rowSums(.[17:21])) %>%\n  mutate(TOTAL = rowSums(.[22:24])) %>%\n  filter(Year == 2018)%>%\n  filter(TOTAL > 0)\n\n\nggtern(data=agpop_mutated,aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point()\n\n\n\n\n\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2015\") +\n  theme_rgbw()\n\n\n\n\n\nlabel <- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\naxis <- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes <- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %>%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05_2.html#heat-maps",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05_2.html#heat-maps",
    "title": "In-class Exercise 5 - Ternary Plots and Heat Maps",
    "section": "Heat Maps",
    "text": "Heat Maps\n\nStatic\n\nrow.names(wh) <- wh$Country\nwh_matrix <- data.matrix(wh)\n\n\nwh_heatmap <- heatmap(wh_matrix)\n\n\n\n\n\nwh_heatmap <- heatmap(wh_matrix,\n                      scale=\"column\",\n                      cexRow = 0.6, \n                      cexCol = 0.8,\n                      margins = c(10, 4))\n\n\n\n\n\n\nInteractive\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          dist_method = \"euclidean\",\n          hclust_method = \"average\",\n          k_row = 3)\n\n\n\n\n\n\nheatmaply(normalize(wh_matrix[, -c(1, 2, 4, 5)]),\n          Colv=NA,\n          seriate = \"none\",\n          colors = Blues,\n          k_row = 5,\n          margins = c(NA,200,60,NA),\n          fontsize_row = 4,\n          fontsize_col = 5,\n          main=\"World Happiness Score and Variables by Country, 2018 \\nDataTransformation using Normalise Method\",\n          xlab = \"World Happiness Indicators\",\n          ylab = \"World Countries\"\n          )"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05_3.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05_3.html",
    "title": "In-class Exercise 5 - Parallel Coordinates Plots",
    "section": "",
    "text": "Loading Packages and Importing Dataset\n\npacman::p_load(GGally, parallelPlot, tidyverse)\nwh <- read_csv(\"data/WHData-2018.csv\")\n\nUsing boxplot()\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Parallel Coordinates Plot of World Happines Variables\")\n\n\n\n\nWith facet wrap and x-axis labels at 30 deg rotation.\n\nggparcoord(data = wh, \n           columns = c(7:12), \n           groupColumn = 2,\n           scale = \"uniminmax\",\n           alphaLines = 0.2,\n           boxplot = TRUE, \n           title = \"Multiple Parallel Coordinates Plots of World Happines Variables by Region\") +\n  facet_wrap(~ Region) + \n  theme(axis.text.x = element_text(angle = 30))\n\n\n\n\n\n\nUsing parallelPlot\n\nwh <- wh %>%\n  select(\"Happiness score\", c(7:12))\nparallelPlot(wh,\n             width = 320,\n             height = 250,\n             rotateTitle = TRUE)\n\n\n\n\n\nwith histogram\n\nhistoVisibility <- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS608-VAA",
    "section": "",
    "text": "Welcome to ISSS608 Visual Analytics and Applications. In this website, you will find my coursework prepared for this course."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html",
    "title": "Take-home Exercise 1",
    "section": "",
    "text": "In this take-home exercise, we are required to reveal the demographic structure of Singapore at planning area level, using the age-sex pyramid method. We are further required to display nine selected planning areas in a single view, in a trellis display.\nI have chosen to select the 9 most populous planning areas in Singapore.\nData used for this exercise was sourced from the Singapore Department of Statistics, retrieved on 19/1/2023. (Refer to “Singapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2022”)\nThe data visualisation is available here."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#procedures-used-to-prepare-the-data-visualisation",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#procedures-used-to-prepare-the-data-visualisation",
    "title": "Take-home Exercise 1",
    "section": "Procedures used to prepare the data visualisation",
    "text": "Procedures used to prepare the data visualisation\n\n#1. Data Checking\nLooking at the raw data, we see that each row shows the population count for a particular gender and an age group, for a given type of dwelling located in each sub-zone under every planning area. By using the “Describe…” feature for each column, we find all the possible values in each field and note that there are no missing values. We further note the range of values under “Population” is 0 to 2,300, which is entirely plausible. We conclude that no data cleaning is required.\n\n(Note that column headers have been renamed from the original raw data, for ease of understanding.)\n\n\n#2. New columns “Female” and “Male”\nUsing “Create Calculated Field…” in Data Source, I created two new columns, “Female” and “Male”. This will make it easier to model the X-axis later on.\nThe value in each field under “Female” corresponds to the “Population” value for that row, if the value for “Sex” in that row is “Females”. Otherwise, the value is 0. A snapshot of the formula used is shown below. Similarly, the value in each field under “Male” corresponds to the “Population” value for that row, if the value for “Sex” in that row is “Males”. Otherwise, the value is 0.\n\n\n\n#3. Identify top 9 most populous planning areas\nPlotting SUM(Population) by Planning Area, I am able to identify and keep only the top 9 most populous areas, as shown below.\n\n\n\n#4. Column and row indices for trellis display\n(For this step, I relied heavily on this excellent tutorial on creating trellis charts, by Youtuber sqlbelle.)\nWe are able to display the 9 age-sex pyramids in a 3x3 display by setting up column and row indices. There are four steps to doing this:\nStep 1: In a worksheet, under “Data”, create a new calculated field which we can call “Index”. This returns the index for the current row in the partition.\n\nStep 2: Under “Data”, create a parameter called “No_of_Columns”. We give this a current value of 3, an integer, which is the number of columns we would like in our trellis matrix. Creating a parameter makes it easier to adjust how many columns we need in future, in case e.g. we wish to include more planning areas.\n\nStep 3: Create a new calculated field called “Columns”. This will “label” each planning area with a column number 1, 2 or 3, and ensure that each number does not appear more times than the number of rows in our trellis matrix.\n\nStep 4: Then create a new calculated field called “Rows” which will label each planning area with a row number 0, 1 or 2.\n\nFor all three new fields “Index”, “Columns” and “Rows”, I convert the field value to discrete by choosing the appropriate option from the dropdown menu on each field in the Data panel.\nBy dragging “Planning Area” to Columns and dragging both “Columns” and “Rows” to “Text”, I am able to check the assignment of column and row numbers to each planning area. It looks like this:\n\nI note that the planning areas are alphabetically ordered, following the original data set. I will return to this issue later.\n\n\n#5. Create the pyramids\nStep 1: Drag “Planning Area” onto “Colour” on the Marks card. This will automatically distinguish different charts for different planning areas by colour. (There is also a possibility of dragging “Planning Area” onto “Detail”, to set the level of detail at which the charts are to be distinguished, i.e. by planning area. However, I eventually chose against this, and will explain why later.)\nStep 2: Drag “Columns’,”Female” and “Male” to columns. Tableau automatically chooses “SUM(Female)” and “SUM(Male)”. This is what I want so I do not change it. In the drop-down list for “Columns”, I click on “Compute Using” and choose “Planning Area”.\nStep 3: Drag “Rows” and “Age Group” to rows. In the drop-down list for “Rows”, I click on “Compute Using” and choose “Planning Area”.\nStep 4: Since pyramid charts are desired, I need to reverse the bars for the left-hand panes in each planning area’s chart, i.e. the pane showing SUM(Female). I do this by right-clicking on the x-axis for “Female”, choosing “Edit axis” and ticking the check-box next to “Reversed”.\nStep 5: The main issue now is that while the planning areas are distinguished by colour, within each planning area the colours for both Female and Male bars are the same. I am not able to change this (or rather, I do not know how!). However, I am able to change the background colour of the panes. I do this by right-clicking on “Males” in the x-axis, and clicking on “Format”. The Format panel appears on the right, and I click on the “Shading” icon at the top. Under “Column banding”, I am able to choose a new background colour for all “Male” panes. This makes it easier to visually distinguish the “Female” and “Male” bars.\nA few further changes are needed to aid visual analysis:\n\nThe Age-Group labels can be ordered in descending fashion by clicking on the sorting icon next to “Age-Group”. This sorting method puts the age group “5_to_9” between “45_to_49” and “50_to_55”, so I have to manually move it to the correct position.\nI can reorder the planning areas in the trellis in descending order of their respective total population sizes, simply by reordering their positions in the legend at the upper right corner.\nOn the Marks card, for both SUM(Female) and SUM(Male), I click on “Label”, tick the check-box next to “Show mark labels”, click on “Min/Max” and choose only the option of labelling the maximum value. (In all planning areas, it is very clear that the smallest age groups are those 90 and over, hence there is no additional value in labelling these.)\n\n\n\n\nOther comments on procedures\nI note that if I had dragged “Planning Area” to “Detail” instead, the colours for Female and Male bars would be different. This would traditionally be how pyramid charts are presented. However, I encountered two problems. First, I could not figure out how to label each chart with the planning area’s name except manually. Second, I was unable to reorder the charts to show descending order of total population size for each planning area, except by using a new data file which had the planning areas in the desired order. As there were only 9 planning areas of interest, the additional time required to make these changes was not that long, however, it would be very troublesome if the number of planning areas displayed was larger. Hence I opted against this version, shown below.\n\nAnother way to maintain traditional bi-coloured pyramid charts was simply to avoid the creation of a trellis altogether, and have the planning areas lined up in a single row. This format also allowed for easy re-ordering of the planning areas in descending order of total population size. Personally, I also thought it was easier for comparison purposes. Just for interest, this version is also shown, below."
  },
  {
    "objectID": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#discussion",
    "href": "Take-home_Ex/Take-home_Ex01/Take-home_Ex01.html#discussion",
    "title": "Take-home Exercise 1",
    "section": "Discussion",
    "text": "Discussion\nIn general, the widest parts of all pyramids are in the middle, indicating a larger adult and elderly population, and fewer young people. That all 9 planning areas demonstrate this could suggest an overall aging population in Singapore, rather than the possibility that certain planning areas attract more adults and elderly than others.\nThe elderly (65 years and over) as a proportion of total residents is generally the same across all areas. In absolute terms, Bedok, Tampines and Hougang appear to have the largest number of residents who are very elderly (80 years and over). This could have implications for town-planning in terms of accommodating accessibility and mobility (e.g. more lifts and ramps, wider and level footpaths to accommodate mobility aids), and preventing potential hazards (e.g. avoiding shared-use paths), for the elderly. It may also mean that these areas require more public healthcare facilities such as polyclinics, since the elderly are more likely to require healthcare services but are also less likely to be able to afford private healthcare. More geriatric services may also be required.\nIn contrast, young people (up to 14 years) as a proportion of total residents is more variable across areas. For example, this proportion is much larger in Sengkang and Punggol. This also has implications for town-planning in terms of providing more active spaces designed for younger people, as well as the need for a higher concentration of schools.\nIn all areas except Bedok and Jurong West, we see a pattern of widening at two points. The age groups at each of the widest two points are about a generation (30 years) apart. For example, the pyramid for Tampines widens towards the age group 30 – 34 years, and again at 60 – 64 years. The pyramid for Punggol widens towards the age group 5 – 9 years, and again at 35 – 39 years. This could suggest two-generational households forming a majority of residents in these planning areas (adults with their parents in the case of Tampines and young families in the case of Punggol). However, for Bedok and Jurong West, a deeper dive may be needed to see if there is a higher proportion of elderly living alone or with their spouses, as they may require more social care.\nIn general, the numbers of females and males living in each area are fairly balanced. In all planning areas except Woodlands and Choa Chu Kang, the largest age groups for both females and males are either the same or adjacent. In Woodlands and Choa Chu Kang, we note that the largest age group for males is 25 – 29 years (and in the range of 50 – 59 for females). This may be because of male work permit or S Pass holders living in these areas – Woodlands is close to the causeway to Johor Bahru, Malaysia, while there is a large industrial zone in Choa Chu Kang. Assuming the overall global trend that most crime is committed by young males, from a security perspective, these areas may warrant closer observation."
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex02/Take-home_Ex02.html",
    "href": "Take-home_Ex/Take-Home_Ex02/Take-home_Ex02.html",
    "title": "Take-home Exercise 2",
    "section": "",
    "text": "For this exercise, we have been tasked to critique a data visualisation that has been prepared by one of our peers for Take-Home Exercise 1. We are also to suggest ways it can be improved and show how they can be done.\n\n\n\nA data visualisation prepared by a classmate.\n\n\n\n\nThe title of the Tableau Public page where the data viz above was published, was “Singapore Population Distribution by Age”. Unfortunately, it does not provide any indication of the relevant timeframe, or the source of the data. Their absence reduces the usability and credibility of the viz. Further, it is unclear why the nine specific planning areas were chosen, and thus may be misinterpreted to mean that the nine areas comprise all of Singapore’s population. This would be incorrect.\nA key issue with the chart itself is that values on its y-axis decrease as we move further away from the origin. Although age groups are essentially categorical, it can be confusing for the reader since we are mostly trained to understand that values increase the further away they are from the origin. This may lead to misinterpretation, for example that the youngest age groups are also the smallest.\nThat aside, the viz does give an adequate overall view of how the distribution of age and gender in each planning area compares with the others. The pyramid shapes (once inverted with a correction of the y-axis) can tell a story of an aging population that seems relatively gender-balanced. However, we can explore other ways of visualising the data that might uncover other information.\n\n\n\nThe mark labels on the y-axis are quite cluttered and not easy to read. The bars in each chart appear to vary in intensity, possibly increasing in intensity proportionate to the age group’s population point. This is somewhat redundant since the relative lengths of bars do a much better job visually of conveying magnitude. Unfortunately the varying intensities of colours as a whole does not give a pleasing aesthetic. That said, overall the viz looks clean in that there aren’t many unnecessary elements that might make it difficult to read."
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex02/Take-home_Ex02.html#alternative-design",
    "href": "Take-home_Ex/Take-Home_Ex02/Take-home_Ex02.html#alternative-design",
    "title": "Take-home Exercise 2",
    "section": "Alternative Design",
    "text": "Alternative Design\nHere I will explain how the data viz above might be improved.\n\nLaunch Tidyverse and Import Data\nWe will only be using Tidyverse.\n\npacman::p_load(tidyverse)\npop_data <- read_csv(\"data/respopagesextod2022.csv\")\n\n\n\nPreparing the Data\nAs mentioned previously, it was not clear from the data viz why the nine planning areas shown were selected. However, when we examine the data, we find that they correspond with the top nine planning areas in terms of total resident count, as shown below:\n\npop_data %>%                                        \n  group_by(PA) %>%                      \n  summarise_at(vars(Pop),               \n               list(Total_Residents = sum)) %>%\n  arrange(desc(Total_Residents)) \n\n# A tibble: 55 × 2\n   PA            Total_Residents\n   <chr>                   <dbl>\n 1 Bedok                  278640\n 2 Tampines               265690\n 3 Jurong West            258540\n 4 Sengkang               253120\n 5 Woodlands              252510\n 6 Hougang                227540\n 7 Yishun                 222960\n 8 Choa Chu Kang          190330\n 9 Punggol                186270\n10 Bukit Batok            165160\n# … with 45 more rows\n\n\nWe therefore create a subset of the original dataset with only the nine planning areas we need. We can also take the opportunity here to make changes to the dataset that will increase clarity, namely by ensuring that the planning areas are displayed in descending order of resident count. To do this, we can insert the order number before each planning area name, using mutate() and replace().\n\ntop_nine <- pop_data %>%\n  filter(PA %in% c('Bedok', 'Tampines',  'Jurong West',\n                   'Sengkang', 'Woodlands', 'Hougang',\n                   'Yishun', 'Choa Chu Kang', 'Punggol')) %>%\n  mutate(PA = replace(PA, PA == \"Bedok\", \"1. Bedok\")) %>%\n  mutate(PA = replace(PA, PA == \"Tampines\", \"2. Tampines\")) %>%\n  mutate(PA = replace(PA, PA == \"Jurong West\", \"3. Jurong West\")) %>%\n  mutate(PA = replace(PA, PA == \"Sengkang\", \"4. Sengkang\")) %>%\n  mutate(PA = replace(PA, PA == \"Woodlands\", \"5. Woodlands\")) %>%\n  mutate(PA = replace(PA, PA == \"Hougang\", \"6. Hougang\")) %>%\n  mutate(PA = replace(PA, PA == \"Yishun\", \"7. Yishun\")) %>%\n  mutate(PA = replace(PA, PA == \"Choa Chu Kang\", \"8. Choa Chu Kang\")) %>%\n  mutate(PA = replace(PA, PA == \"Punggol\", \"9. Punggol\")) \n\nWe then select only the columns we want, and group the data so that we have a sub-total count of residents for each age group for each gender.\n\nfinal_data <- top_nine %>%  \n  select(PA, AG, Sex, Pop) %>%\n  group_by(PA, AG, Sex) %>%\n  summarise_at(vars(Pop), list(Count = sum))\n\nTo make the y-axis (i.e. age groups) less cluttered and therefore more readable, we can indicate only the lower limit of each group. We can also convert the values to numeric form, to ensure that the values on the y-axis will increase as they move further away from the origin, thus increasing clarity.\n\nfinal_data <- final_data %>%\n  mutate(AG = replace(AG, AG == \"0_to_4\", 0)) %>%\n  mutate(AG = replace(AG, AG == \"5_to_9\", 5)) %>%\n  mutate(AG = replace(AG, AG == \"10_to_14\", 10)) %>%\n  mutate(AG = replace(AG, AG == \"15_to_19\", 15)) %>%\n  mutate(AG = replace(AG, AG == \"20_to_24\", 20)) %>%\n  mutate(AG = replace(AG, AG == \"25_to_29\", 25)) %>%\n  mutate(AG = replace(AG, AG == \"30_to_34\", 30)) %>%\n  mutate(AG = replace(AG, AG == \"35_to_39\", 35)) %>%\n  mutate(AG = replace(AG, AG == \"40_to_44\", 40)) %>%\n  mutate(AG = replace(AG, AG == \"45_to_49\", 45)) %>%\n  mutate(AG = replace(AG, AG == \"50_to_54\", 50)) %>%\n  mutate(AG = replace(AG, AG == \"55_to_59\", 55)) %>%\n  mutate(AG = replace(AG, AG == \"60_to_64\", 60)) %>%\n  mutate(AG = replace(AG, AG == \"65_to_69\", 65)) %>%\n  mutate(AG = replace(AG, AG == \"70_to_74\", 70)) %>%\n  mutate(AG = replace(AG, AG == \"75_to_79\", 75)) %>%\n  mutate(AG = replace(AG, AG == \"80_to_84\", 80)) %>%\n  mutate(AG = replace(AG, AG == \"85_to_89\", 85)) %>%\n  mutate(AG = replace(AG, AG == \"90_and_over\", 90)) %>%\n  mutate_at(c('AG'), as.numeric)\n\nTo reverse the bars for the male counts, we create another column which has the female count as a positive number and the male count as a negative number.\n\nfinal_data <- final_data %>%\n  group_by(Sex) %>% \n  mutate(Population = ifelse(Sex == \"Females\", Count,-Count))\n\nThen we plot the age-sex pyramids for each planning area, in a trellis display. In doing so, we also add a title which explains the selection of the nine planning areas and the timeframe, as well as a caption mentioning the data’s source. As the default colour options are clear and aesthetically pleasing, we don’t need to further change them.\n\nplotted <- ggplot(final_data, aes(x = AG, Population, fill = Sex)) + \n  geom_bar(data = filter(final_data, Sex == \"Females\"), stat = \"identity\") + \n  geom_bar(data = filter(final_data, Sex == \"Males\"),  stat = \"identity\") + \n  scale_y_continuous(breaks = seq(-10000, 10000, 2500), \n                     labels = abs(seq(-10, 10, 2.5))) +\n  scale_x_continuous(breaks = seq(0, 90, 5)) +\n  coord_flip() +\n  facet_wrap(~ PA) +\n  labs(x = \"Lower Limit of Age Group (years)\", y = \"Resident Count (thousands)\",\n       title = \"Age-Sex Pyramids of 9 Most Populous Planning Areas in Singapore (June 2022)\",\n       caption = \"Data sourced from the Singapore Department of Statistics\") \n\nplotted\n\n\n\n\nWhile the above chart provides a good overview of the relative shapes of the age-sex pyramids, we might be interested to know which age group is the largest for each gender in each planning area.\nTo do this, first we create a new column in the dataset, called “Key”. The value in this column would be the count if the row corresponds with the largest age group for a gender in a planning area. If it is not the largest age group, then the value is simply a character space (i.e. a blank).\n\nfinal_data2 <- final_data %>%\n  group_by(PA, Sex) %>% \n  mutate(Key = ifelse((max(Count) == Count), Count/1000, \" \"))\n\nThen we can label the largest age groups using geom_text(). We also add a caption to explain what each label means.\n\nplotted2 <- ggplot(final_data2, aes(x = AG, Population, fill = Sex)) + \n  geom_bar(data = filter(final_data2, Sex == \"Females\"), stat = \"identity\") + \n  geom_bar(data = filter(final_data2, Sex == \"Males\"),  stat = \"identity\") + \n  geom_text(aes(label=Key)) +\n  scale_y_continuous(breaks = seq(-10000, 10000, 2500), \n                     labels = abs(seq(-10, 10, 2.5))) +\n  scale_x_continuous(breaks = seq(0, 90, 5)) +\n  coord_flip() +\n  facet_wrap(~ PA) +\n  labs(x = \"Lower Limit of Age Group (years)\", y = \"Resident Count (thousands)\",\n       title = \"Age-Sex Pyramids of 9 Most Populous Planning Areas in Singapore (June 2022)\", \n       caption = \"Largest age groups for each gender in each planning area, are indicated with their count.\\n Data sourced from the Singapore Department of Statistics\")\n\nplotted2\n\n\n\n\nWhile this makes it easier to see the values corresponding to each of the largest age groups, perhaps our main interest is to convey anomalies and we are less interested in the detailed values. Instead of labelling the largest age groups with their count values, perhaps we can highlight the corresponding bars instead.\nTo do this, we need to create a new column, similar to what we did before. The difference here is that we then apply it to the chart’s aesthetic fill (i.e. the colours of the bars).\n\nfinal_data3 <- final_data %>%\n  group_by(PA, Sex) %>% \n  mutate(Key = ifelse((max(Count) == Count), \"Largest Age Group\", NA))\n\nplotted3 <- ggplot(final_data3, aes(x = AG, Population, fill = Key)) + \n  geom_bar(data = filter(final_data3, Sex == \"Females\"), stat = \"identity\") + \n  geom_bar(data = filter(final_data3, Sex == \"Males\"),  stat = \"identity\") + \n  scale_y_continuous(breaks = seq(-10000, 10000, 2500), \n                     labels = abs(seq(-10, 10, 2.5))) +\n  scale_x_continuous(breaks = seq(0, 90, 5)) +\n  coord_flip() +\n  facet_wrap(~ PA) +\n  labs(x = \"Lower Limit of Age Group (years)\", y = \"Resident Count (thousands)\",\n       title = \"Largest Age Groups, Male and Female\",\n       caption = \"Male resident count shown to the left of each panel, female to the right.\\n Data sourced from the Singapore Department of Statistics\")\n\nplotted3\n\n\n\n\nWe see from the above a more visually striking contrast between the two planning areas that have a large difference between the largest age groups for the two genders, and the others. However, I was only able to explain that the male resident count is too the left of each panel, and female to the right. I am sure there is a more elegant way that I haven’t figured out yet!"
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex02/Take-home_Ex02.html#conclusion",
    "href": "Take-home_Ex/Take-Home_Ex02/Take-home_Ex02.html#conclusion",
    "title": "Take-home Exercise 2",
    "section": "Conclusion",
    "text": "Conclusion\nWhile there are many ways to change the appearance and content, they should be determined by the message(s) we plan to convey with the data viz. The above are merely some suggestions to improve clarity and aesthetics without adding too much content, and in the absence of the original owner’s intentions. This exercise has also helped me realise the improvements I could have made with my own data viz for Take-home Exercise 1."
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex02/Take-home_Ex02.html#extra",
    "href": "Take-home_Ex/Take-Home_Ex02/Take-home_Ex02.html#extra",
    "title": "Take-home Exercise 2",
    "section": "Extra",
    "text": "Extra\nThe following was added after the deadline for this exercise. We were asked in class to consider displaying the pyramids in a manner that would allow direct contrast with the age-sex pyramid shape for the total population of Singapore. Here goes.\n\nTop_Nine <- top_nine %>%\n  group_by(PA, AG, Sex) %>%\n  summarise(Count = sum(Pop)) %>%\n  group_by(PA) %>%\n  mutate(percentofPA = (Count/sum(Count))*100) %>%\n  select(PA, AG, Sex, percentofPA)\n\n\nSingapore <- pop_data %>%\n  group_by(AG, Sex) %>%\n  summarise(Count = sum(Pop)) %>%\n  ungroup(AG, Sex) %>%\n  mutate(percentofSG = (Count/sum(Count))*100)\n\n\nFinal <- left_join(Top_Nine, Singapore, by = c('AG'='AG', 'Sex'='Sex'))\n\n\nFinal1 <- Final %>%\n  mutate(AG = replace(AG, AG == \"0_to_4\", 0)) %>%\n  mutate(AG = replace(AG, AG == \"5_to_9\", 5)) %>%\n  mutate(AG = replace(AG, AG == \"10_to_14\", 10)) %>%\n  mutate(AG = replace(AG, AG == \"15_to_19\", 15)) %>%\n  mutate(AG = replace(AG, AG == \"20_to_24\", 20)) %>%\n  mutate(AG = replace(AG, AG == \"25_to_29\", 25)) %>%\n  mutate(AG = replace(AG, AG == \"30_to_34\", 30)) %>%\n  mutate(AG = replace(AG, AG == \"35_to_39\", 35)) %>%\n  mutate(AG = replace(AG, AG == \"40_to_44\", 40)) %>%\n  mutate(AG = replace(AG, AG == \"45_to_49\", 45)) %>%\n  mutate(AG = replace(AG, AG == \"50_to_54\", 50)) %>%\n  mutate(AG = replace(AG, AG == \"55_to_59\", 55)) %>%\n  mutate(AG = replace(AG, AG == \"60_to_64\", 60)) %>%\n  mutate(AG = replace(AG, AG == \"65_to_69\", 65)) %>%\n  mutate(AG = replace(AG, AG == \"70_to_74\", 70)) %>%\n  mutate(AG = replace(AG, AG == \"75_to_79\", 75)) %>%\n  mutate(AG = replace(AG, AG == \"80_to_84\", 80)) %>%\n  mutate(AG = replace(AG, AG == \"85_to_89\", 85)) %>%\n  mutate(AG = replace(AG, AG == \"90_and_over\", 90)) %>%\n  mutate_at(c('AG'), as.numeric)\n\n\nFinal6 <- Final1 %>%\n  select(PA, AG, Sex, percentofPA, percentofSG) %>%\n  mutate(Category = \"A\") %>%\n  mutate(PerCent = ifelse(percentofPA<=percentofSG, (percentofSG - percentofPA), 0)) %>%\n  group_by(PA, AG, Sex, percentofPA, percentofSG) %>%\n  group_modify(~ add_row(., Category = \"B\")) %>%\n  group_modify(~ add_row(., Category = \"C\")) %>%\n  group_modify(~ add_row(., Category = \"D\")) %>%\n  mutate(PerCent = ifelse(Category == \"B\" & percentofPA>percentofSG, (percentofPA - percentofSG), PerCent)) %>%\n  mutate(PerCent = ifelse(Category == \"C\" & percentofSG<percentofPA, percentofSG, PerCent)) %>%\n  mutate(PerCent = ifelse(Category == \"D\" & percentofSG>=percentofPA, percentofPA, PerCent)) %>%\n  replace(is.na(.), 0) %>% \n  mutate(PerCent = ifelse(Sex == \"Females\", PerCent,-PerCent))\n\n\nplotted2 <- ggplot(Final6, aes(x = AG, PerCent, fill = Sex)) + \n  geom_bar(data = filter(Final6, Sex == \"Females\"), stat = \"identity\", aes(fill = Category)) + \n  geom_bar(data = filter(Final6, Sex == \"Males\"),  stat = \"identity\", aes(fill = Category)) + \n  scale_fill_manual(values = c('gray70', 'rosybrown1', 'rosybrown', 'rosybrown')) + \n  coord_flip() +\n  scale_y_continuous(breaks = seq(-5, 5, 2.5), \n                     labels = abs(seq(-5, 5, 2.5))) +\n  scale_x_continuous(breaks = seq(0, 90, 5)) + \n  facet_wrap(~ PA) +\n  theme(legend.position=\"none\") +\n  labs(x = \"Lower Limit of Age Group (years)\", y = \"Resident Count (%)\",\n       title = \"Age-Sex Pyramids of 9 Most Populous Planning Areas in Singapore (June 2022)\", \n       subtitle = \"Compared to Total Singapore Age-Sex Distribution\", \n       caption = \"Data sourced from the Singapore Department of Statistics\\n Planning Area pyramid shown as translucent pink, Singapore pyramid shown as translucent gray\") \n\nplotted2"
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex03/Take-home_Ex03.html",
    "href": "Take-home_Ex/Take-Home_Ex03/Take-home_Ex03.html",
    "title": "Take-home Exercise 3",
    "section": "",
    "text": "In this exercise, we are tasked with building data visualisations using a dataset of HDB resale prices for sales registered since 1 January 2017 (source: Data.gov.sg)."
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex03/Take-home_Ex03.html#loading-packages-and-importing-dataset",
    "href": "Take-home_Ex/Take-Home_Ex03/Take-home_Ex03.html#loading-packages-and-importing-dataset",
    "title": "Take-home Exercise 3",
    "section": "Loading packages and importing dataset",
    "text": "Loading packages and importing dataset\n\npacman::p_load(ggstatsplot, performance, ggiraph, plotly, FunnelPlotR, tidyverse, patchwork)\n\n\nresale_data <- read_csv(\"data/resale-flat-prices-based-on-registration-date-from-jan-2017-onwards.csv\")\n\nAs the assignment requires us to focus our study on the time period 2022 and the flat types “3-ROOM”, “4-ROOM” and “5-ROOM”, we can filter the required data as follows:\n\nresale_data2022 <- resale_data %>%\n  filter(grepl(\"2022\", month), flat_type == \"3 ROOM\" | flat_type == \"4 ROOM\" | flat_type == \"5 ROOM\")"
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex03/Take-home_Ex03.html#resale-prices-by-flat-type",
    "href": "Take-home_Ex/Take-Home_Ex03/Take-home_Ex03.html#resale-prices-by-flat-type",
    "title": "Take-home Exercise 3",
    "section": "1. Resale prices by flat type",
    "text": "1. Resale prices by flat type\n\nDescription:\nWe wish to compare resale prices by flat-type. Since it is expected that resale prices would be higher for larger flats (assuming “larger” refers to number of rooms, therefore e.g. 5-room flats are more expensive than 4-room flats), we will instead use price per square foot (psf) as our measure. Price psf is often used in the property sector.\nA common assumption is that larger units would have lower price psf. We can investigate if this is true, while examining the means and distributions of prices psf for each flat-type. We first compute price psf (using 1 sqm = 10.764 sqft), then use ggbetweenstats() to conduct a One-way ANOVA test on price psf by flat-type.\n\nresale_data2022_psf <- resale_data2022 %>%\n  mutate(RPpsf = (resale_price/floor_area_sqm)/10.764)   \n\n\nggbetweenstats(\n  data = resale_data2022_psf,\n  x = flat_type, \n  y = RPpsf,\n  type = \"p\",\n  pairwise.comparisons = TRUE, \n  pairwise.display = \"s\",\n  messages = FALSE,\n  xlab = \"Flat Type\",\n  ylab = \"Price per Square Foot\",\n  title = \"One-way ANOVA test on Price per square foot by flat type\",\n  subtitle = \"Resale prices for 3, 4 and 5-room HDB flats in 2022\"\n  ## Note that we can go along with default method (\"holm\") for p-value adjustment\n)\n\n\n\n\n\nPatterns revealed:\nFirst, we note that the differences between the mean prices psf of the three flat-types are statistically significant at the 95% confidence level. Second, we see that the mean price psf for 4-room flats is higher than that for 3-room flats, going against the usual assumption. However, it is also observed that the distance between mean and median, as well as the distance between the median and the maximum value (excluding outliers), are much higher for 4-room flats compared to the other two flat-types. There is more variance at the upper end of prices psf for 4-room flats."
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex03/Take-home_Ex03.html#correlation-between-resale-price-and-remaining-lease",
    "href": "Take-home_Ex/Take-Home_Ex03/Take-home_Ex03.html#correlation-between-resale-price-and-remaining-lease",
    "title": "Take-home Exercise 3",
    "section": "2. Correlation between Resale Price and Remaining Lease",
    "text": "2. Correlation between Resale Price and Remaining Lease\nDescription:\nIt is expected that the remaining lease on a flat would influence its resale price. We’re interested to find out if there is a difference in the strengths of the correlations across the three flat-types. To visualise this, we use ggscatterstats(). In addition, we can investigate whether remaining lease is independent of or associated with flat-type, using ggbarstats(). We can display these charts in a 2x2 grid using the patchwork package.\nHowever, before using either, we need to convert the remaining lease values to numeric data. From examining the data, we note that remaining lease ranges from 43 to 96 years, when rounded down to the nearest year. We use mutate() and substr() to extract the number of years to a new column.\n\nresale_data2022_yy <- resale_data2022 %>%\n  mutate(rl_yy = as.numeric(substr(remaining_lease, start=1, stop=2)))\n\n\n# Scatterplots with marginal distributions and statistical results,\n# for remaining lease and resale price, three flat types.\n\np1 <- ggscatterstats(\n  data = filter(.data=resale_data2022_yy, flat_type == \"3 ROOM\"),\n  x = rl_yy,\n  y = resale_price,\n  xlab = \"Remaining Lease (years)\",\n  ylab = \"Resale Price (thousands)\",\n  title = \"3 ROOM\"\n) +\n  scale_y_continuous(breaks = seq(100000, 1500000, 200000),\n                     labels = seq(100, 1500, 200))\n\np2 <- ggscatterstats(\n  data = filter(.data=resale_data2022_yy, flat_type == \"4 ROOM\"),\n  x = rl_yy,\n  y = resale_price,\n  xlab = \"Remaining Lease (years)\",\n  ylab = \"Resale Price (thousands)\",\n  title = \"4 ROOM\"\n) +\n  scale_y_continuous(breaks = seq(100000, 1500000, 200000),\n                     labels = seq(100, 1500, 200))\n\np3 <- ggscatterstats(\n  data = filter(.data=resale_data2022_yy, flat_type == \"5 ROOM\"),\n  x = rl_yy,\n  y = resale_price,\n  xlab = \"Remaining Lease (years)\",\n  ylab = \"Resale Price (thousands)\",\n  title = \"5 ROOM\"\n) +\n  scale_y_continuous(breaks = seq(100000, 1500000, 200000),\n                     labels = seq(100, 1500, 200))\n\n## Stacked bar charts with statistical tests,\n## for test of association between flat type and remaining lease\n\nresale_data2022_yy1 <- resale_data2022_yy %>% \n  mutate(rl_yy_bins = cut(rl_yy, breaks = c(0,55,70,85,100))\n)\n\np4 <- ggbarstats(resale_data2022_yy1, \n           x = rl_yy_bins, \n           y = flat_type,\n           title = \"Significance Test of Association\",\n           legend.title = \"Remaining Lease Bins\",\n           xlab = \"Flat Type\")\n\np1 + p2 + p3 + p4\n\n\n\n\n\nPatterns revealed:\nThere is significant linear relationship between remaining lease and resale price for all three flat-types. The Pearson’s correlation coefficient shows positive relationship for all three flat-types, and is strongest for 3-room flats while weakest for 5-room flats. We are also able to observe this from the scatterplots, which show greatest distribution of points for 5-room flats. The marginal distributions for each flat-type indicate that while resale prices are somewhat normally distributed, remaining lease years are not. The latter is reflected in the stacked bar charts and test results, which show significant association between flat-type and remaining lease."
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex03/Take-home_Ex03.html#regression-model-for-resale-price",
    "href": "Take-home_Ex/Take-Home_Ex03/Take-home_Ex03.html#regression-model-for-resale-price",
    "title": "Take-home Exercise 3",
    "section": "3. Regression model for Resale Price",
    "text": "3. Regression model for Resale Price\nDescription:\nWe would like to be able to predict resale price based on a flat’s characteristics, by building a regression model using lm(). We will use number of rooms, storey range, floor area and remaining lease. As there are currently 17 categories in storey range, we will reduce it to five categories by creating a category for 13th storey and above. Then we will convert the desired character columns to factors, so that R automatically treats those variables as reference dummies when running the regression.\nWe will also use check_model() to check that the model satisfies the assumptions for a multiple linear regression model.\nAlthough address (town, street name and block) is expected to affect resale price, there would be too many addresses with too few observations each, hence we exclude it from the model. Flat model is also omitted as the metadata does not include an explanation for this variable.\n\nfor_regression <- resale_data2022_yy %>%\n  mutate(start_range = if_else(\n    storey_range == \"01 TO 03\" | \n      storey_range == \"04 TO 06\" | \n      storey_range == \"07 TO 09\" | \n      storey_range == \"10 TO 12\", storey_range, \"13 OR MORE\")) %>%\n  mutate_at(c(\"flat_type\", \"start_range\"), as.factor)\n\n\nrp_model <- lm(resale_price ~ flat_type + start_range + \n              floor_area_sqm + rl_yy, data = for_regression)\n\n\ncheck_model(rp_model)\n\n\n\n\n\nrp_model1 <- lm(resale_price ~ start_range + \n              floor_area_sqm + rl_yy, data = for_regression)\n\nsummary(rp_model1)\n\n\nCall:\nlm(formula = resale_price ~ start_range + floor_area_sqm + rl_yy, \n    data = for_regression)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-265726  -64778  -19495   35269  715432 \n\nCoefficients:\n                        Estimate Std. Error t value Pr(>|t|)    \n(Intercept)           -135848.89    4568.41 -29.737   <2e-16 ***\nstart_range04 TO 06     19395.70    2179.50   8.899   <2e-16 ***\nstart_range07 TO 09     35285.45    2211.63  15.954   <2e-16 ***\nstart_range10 TO 12     42229.18    2281.88  18.506   <2e-16 ***\nstart_range13 OR MORE  129110.46    2273.17  56.798   <2e-16 ***\nfloor_area_sqm           4176.22      35.69 117.005   <2e-16 ***\nrl_yy                    3136.99      47.90  65.497   <2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 105500 on 24365 degrees of freedom\nMultiple R-squared:  0.5542,    Adjusted R-squared:  0.554 \nF-statistic:  5047 on 6 and 24365 DF,  p-value: < 2.2e-16\n\n\n\nPatterns revealed:\nAs there was high collinearity observed between flat type and floor area in the first regression model, we ran another regression model which excluded flat type. The results show significant linear relationships between each independent variable and resale price, at 95% confidence level. It is observed that flats on higher storeys command higher resale prices, all other variables kept equal. The large coefficients for floor area and remaining lease years also show strong influence on resale price. However, adjusted R-squared indicates this model explains only 55% of variability, suggesting that there are other factors to consider when predicting resale price."
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex03/Take-home_Ex03.html#uncertainty-in-mean-resale-price",
    "href": "Take-home_Ex/Take-Home_Ex03/Take-home_Ex03.html#uncertainty-in-mean-resale-price",
    "title": "Take-home Exercise 3",
    "section": "4. Uncertainty in mean Resale Price",
    "text": "4. Uncertainty in mean Resale Price\nDescription:\nWe would like to visualise the uncertainty of point estimates with regard to mean resale prices by flat type. We can do this using geom_errorbar() with interactive mean points which show the 95% confidence interval. However, first we need to group observations and tabulate count, mean, standard deviation and standard error for each group.\n\nmy_sum <- resale_data2022 %>%\n  group_by(flat_type) %>%\n  summarise(\n    n = n(),\n    mean = mean(resale_price),\n    sd = sd(resale_price)\n  ) %>%\n  mutate(se = sd/sqrt(n-1))\n\nmy_sum\n\n# A tibble: 3 × 5\n  flat_type     n    mean      sd    se\n  <chr>     <int>   <dbl>   <dbl> <dbl>\n1 3 ROOM     6345 388904.  85288. 1071.\n2 4 ROOM    11311 549079. 129347. 1216.\n3 5 ROOM     6716 654373. 144236. 1760.\n\n\n\ntcrit <- qnorm(0.025)\n\nmy_sum$tooltip <- c(paste0(\n  \"Flat type = \", my_sum$flat_type,\n  \"\\n N = \", my_sum$n,\n  \"\\n Avg. Resale Price = \", as.integer(my_sum$mean),\n  \"\\n 95% CI: [\", as.integer(my_sum$mean+(tcrit*my_sum$se)), \" , \", as.integer(my_sum$mean-(tcrit*my_sum$se)), \"]\"\n))\n\np <- ggplot(my_sum) +\n  geom_errorbar(\n    aes(x = reorder(flat_type, -mean), ymin = mean+(tcrit*se), ymax = mean-(tcrit*se)),\n    width = 0.2, colour = \"black\", alpha = 0.9, size = 0.5) +\n  scale_y_continuous(breaks = seq(400000, 700000, 50000),\n                     labels = seq(400, 700, 50)) +\n  geom_point_interactive(\n    aes(x = reorder(flat_type, -mean), y = mean, tooltip = my_sum$tooltip), \n    stat = \"identity\", colour = \"red\", size = 1.5, alpha = 1) +\n  ggtitle(\"Standard error of mean resale price by flat type\") +\n  labs(x = \"Flat Type\", y = \"Resale Price (thousands)\")\n\ngirafe(ggobj = p,\n       width_svg = 8,\n       height_svg = 8*0.618\n)\n\n\n\n\n\n\nPatterns revealed:\nThe above shows that the mean resale price for 5-room flats has the widest 95% confidence interval. (Given the differences in mean resale price for the three flat types and the constraints of the plot, it is a bit difficult to see the exact values in each confidence interval. However the interactive mean points display these clearly for the reader.)"
  },
  {
    "objectID": "Take-home_Ex/Take-Home_Ex03/Take-home_Ex03.html#x.-street-performance-resale-prices-that-exceed-predicted",
    "href": "Take-home_Ex/Take-Home_Ex03/Take-home_Ex03.html#x.-street-performance-resale-prices-that-exceed-predicted",
    "title": "Take-home Exercise 3",
    "section": "X. Street performance (resale prices that exceed predicted)",
    "text": "X. Street performance (resale prices that exceed predicted)\nDescription:\nLet’s say we wish to compare the performance of different towns or different streets in Singapore, where performance is measured by whether a street’s HDB resale prices have exceeded expectations. The expected resale price is predicted by our earlier regression model (rp_model1). Perhaps we could visualise this on a funnel plot, using funnel_plot().\nFirst, I have created a new column containing the predicted resale prices, by using the intercept and coefficients from rp_model1. This is to allow me to obtain, for each town, the number of sales which resale prices exceeded expectations.\n\nresale_data2022_prd <- for_regression %>%\n  mutate(predicted = -135849 +\n           (19396*ifelse(flat_type == \"04 TO 06\", 1, 0)) +\n           (35285*ifelse(flat_type == \"07 TO 09\", 1, 0)) +\n           (42229*ifelse(flat_type == \"10 TO 12\", 1, 0)) +\n           (129110*ifelse(flat_type == \"13 OR MORE\", 1, 0) +\n              (4176*floor_area_sqm) +\n              (3137*rl_yy)))\n\nFirst, trying out the funnel plot with town as group.\n\nfor_funnelplot <- resale_data2022_prd %>%\n  mutate(exceeded = ifelse(resale_price > predicted, 1, 0)) %>%\n  group_by(town) %>%\n  summarise(total_exceeded = sum(exceeded), n = n())\n\n\nfunnel_plot(\n  numerator = for_funnelplot$total_exceeded,\n  denominator = for_funnelplot$n,\n  group = for_funnelplot$town,\n  data_type = \"PR\",\n  title = \"Cumulative Rate of Resale Prices Exceeding Predicted by\\n Cumulative Resale Transactions\",\n  x_label = \"Cumulative Resale Transactions\",\n  y_label = \"Cumulative Rate of Resale Prices\\n Exceeding Predicted\"\n)\n\n\n\n\nA funnel plot object with 26 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\nThis looks odd. Next, try funnel plot with street as group.\n\nfor_funnelplot1 <- resale_data2022_prd %>%\n  mutate(exceeded = ifelse(resale_price > predicted, 1, 0)) %>%\n  group_by(street_name) %>%\n  summarise(total_exceeded = sum(exceeded), n = n())\n\n\nfunnel_plot(\n  numerator = for_funnelplot1$total_exceeded,\n  denominator = for_funnelplot1$n,\n  group = for_funnelplot1$street_name,\n  data_type = \"PR\",\n  title = \"Cumulative Rate of Resale Prices Exceeding Predicted by\\n Cumulative Resale Transactions\",\n  x_label = \"Cumulative Resale Transactions\",\n  y_label = \"Cumulative Rate of Resale Prices\\n Exceeding Predicted\"\n)\n\n\n\n\nA funnel plot object with 552 points of which 0 are outliers. \nPlot is adjusted for overdispersion. \n\n\n\nThis plot also looks odd - nothing like a funnel. Perhaps it is because the measures of variation are not well-developed enough. According to this paper by the Canadian Institute for Health Information, funnel plots only work for indicators with well-developed measures of variation. Unfortunately no patterns to reveal here!"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "title": "In-class Exercise 6",
    "section": "",
    "text": "This exercise is about working with temporal data.\n\n\n\npacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, tidyverse, readxl, knitr, data.table)\n\n\n\n\nWe will use a data file comprising199,999 rows of time-series cyber attack records, by country.\nImporting the dataset:\n\nattacks <- read_csv(\"data/eventlog.csv\")\n\nExamining the data structure using kable().\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nWe note that:\n\ntimestamp field stores date-time values in POSIXct format (Note: POSIXct stores date and time in seconds with the number of seconds beginning at 1 January 1970. Each date and time is thus a single value in units of seconds. This speeds up computation, processing and conversion to other formats.)\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code\ntz field stores time zone of the source IP address\n\n\n\nStep 1: Deriving wkday and hour fields to enable plotting of the calendar heatmap.\n\nmake_hr_wkday <- function(ts, sc, tz) {\n  real_times <- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt <- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\nStep 2: Deriving the attacks tibble data frame.\n\nwkday_levels <- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks <- attacks %>%\n  group_by(tz) %>%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %>% \n  ungroup() %>% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\nNote: The use of factor() ensures that those variables are ordered during plotting.\nChecking the structure of attacks.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\n\n…\n\ngrouped <- attacks %>% \n  count(wkday, hour) %>% \n  ungroup() %>%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          linewidth = 0.1) + \ntheme_tufte(base_family = \"serif\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\n[NOTES]\n\n\n\nSteps 1 and 2 will identify and extract data on the top 4 countries in terms of number of attacks.\nStep 1: Deriving attack by country object\n\nattacks_by_country <- count(\n  attacks, source_country) %>%\n  mutate(percent = percent(n/sum(n))) %>%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\n\ntop4 <- attacks_by_country$source_country[1:4]\ntop4_attacks <- attacks %>%\n  filter(source_country %in% top4) %>%\n  count(source_country, wkday, hour) %>%\n  ungroup() %>%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %>%\n  na.omit()\n\nNow we plot the multiple heat map using ggplot2.\nStep 3: Plotting the Multiple Calender Heatmaps\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"serif\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )\n\n\n\n\n\n\n\n\nWe will plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam, using ggplot2.\nImporting the dataset:\n\nair <- read_excel(\"data/arrivals_by_air.xlsx\")\n\n…\n\nair$month <- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year <- year(ymd(air$`Month-Year`))\n\n…\n\nVietnam <- air %>% \n  select(`Vietnam`, \n         month, \n         year) %>%\n  filter(year >= 2010)\n\n…\n\nhline.data <- Vietnam %>% \n  group_by(month) %>%\n  summarise(avgvalue = mean(`Vietnam`))\n\n…\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\") +\n  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust=1))"
  }
]